var documenterSearchIndex = {"docs":
[{"location":"migrate/#Migration-guides","page":"Migration guides","title":"Migration guides","text":"","category":"section"},{"location":"migrate/","page":"Migration guides","title":"Migration guides","text":"This guide provides an overview of how to migrate your code from either the pre-1.0 JSON.jl package to the 1.0 release or from JSON3.jl. The 1.0 release introduces several improvements and changes, particularly in how JSON is read and written, leveraging StructUtils.jl for customization and extensibility. Below, we outline the key differences and provide step-by-step instructions for updating your code.","category":"page"},{"location":"migrate/","page":"Migration guides","title":"Migration guides","text":"","category":"page"},{"location":"migrate/#Migration-guide-from-pre-1.0-1.0","page":"Migration guides","title":"Migration guide from pre-1.0 -> 1.0","text":"","category":"section"},{"location":"migrate/#Writing-JSON","page":"Migration guides","title":"Writing JSON","text":"","category":"section"},{"location":"migrate/","page":"Migration guides","title":"Migration guides","text":"JSON.json\nWhat stayed the same:\nProduces a compact String by default\nCan automatically serialize basic structs in a sensible way\nCan take an integer 2nd argument to induce \"pretty printing\" of the JSON output\nWhat changed:\nCan now pass JSON.json(x; pretty=true) or JSON.json(x; pretty=4) to control pretty printing\nCan pass filename as first argument to write JSON directly to a file JSON.json(file, x) the file name is returned\nCan pass any IO as 1st argument to write JSON to it: JSON.json(io, x)\nCircular reference tracking is fixed/improved (previously peer references were written as null)\nExplicit keyword arguments to control a number of serialization features, including:\nomit_null::Bool whether nothing/missing Julia values should be skipped when serializing\nomit_empty::Bool whether empty Julia collection values should be skipped when serializing\nallownan::Bool similar to the parsing keyword argument to allow/disallow writing of invalid JSON values NaN, -Inf, and Inf\nninf::String the string to write if allownan=true and serializing -Inf\ninf::String the string to write if allownan=true and serializing Inf\nnan::String the string to write if allownan=true and serializing NaN\njsonlines::String when serializing an array, write each element independently on a new line as an implicit array; can be read back when parsing by also passing jsonlines=true\ninline_limit::Int threshold number of elements in an array under which an array should be printed on a single line (only applicable when pretty printing)\nfloat_style::Symbol allowed values are :shortest, :fixed, and :exp corresponding to printf format styles, %g, %f, and %e, respectively\nfloat_precision::Int number of decimal places to use when printing floats\nWhy the changes:\nMostly just modernizing the interfaces (use of keyword arguments vs. positional)\nUtilizing multiple dispatch to combine JSON.print and JSON.json and provide convenience for writing to files\nMost opened issues over the last few years were about providing more controls around writing JSON without having to completely implement a custom serializer\nMore consistency with JSON.parse keyword args with allownan and jsonlines\nJSON.print\nWhat stayed the same:\nTechnically still defined for backwards compatibility, but just calls JSON.json under the hood\nWhy the changes:\nNot necessary as all the functionality can be combined without ambiguity or overlap with JSON.json\nJSON.lower\nWhat stayed the same:\nStill used to transform Julia values into JSON-appropriate values\nWhat changed:\nlower technically now lives in the StructUtils.jl package (though overloading in JSON is fine)\nCan overload for a specific \"style\" for non-owned types, like struct MyStyle <: JSON.JSONStyle end, then JSON.lower(::MyStyle, x::Rational) = (den=x.den, num=x.num), then have the style used when writing like JSON.json(1//3; style=MyStyle())\nProbably don't need to lower except in rare cases; there are default lower defintions for common types and most structs/AbstractDict/AbstractArray will work out of the box; lower is mostly useful when wanting to have the JSON output of a struct be a string or a number, for example, so going between aggregate/non-aggregate from Julia to JSON\nWhy the changes:\nAlong with the new corresponding lift interface, the lower + lift combination is a powerful generalization of doing \"domain transformations\"\nJSON.StructuralContext / JSON.show_json / JSON.Serialization\nWhat stayed the same:\nThese have been removed in favor of simpler interfaces and custom JSONStyle subtypes + overloads\nWhy the changes:\nThe use of distinct contexts for different writing styles (pretty, compact) is unnecessary and led to code duplication\nThere was often confusion about whether a custom Serialization or StructuralContext was needed and what intefaces were then required to implement\nThe need to customize separators, delimiters, and indentation, while powerful, can be accomplished much simpler via keyword arguments or is not necessary at all (i.e. JSON.jl shouldn't be too concerned with how to produce anything that isn't JSON)\nInstead of overloading showstring/showelement/showkey/showpair/showjson, lower can be used to accomplish any requirements of \"overloading\" how values are serialized; the addition of \"styles\" also allows customizing for non-owned types instead of needing a custom context + `showjson` method\nJSONText\nWhat changed:\nNothing; JSONText can still be used to have a JSON-formatted string be written as-is when serializing","category":"page"},{"location":"migrate/#Reading-JSON","page":"Migration guides","title":"Reading JSON","text":"","category":"section"},{"location":"migrate/","page":"Migration guides","title":"Migration guides","text":"JSON.parse / JSON.parsefile\nWhat stayed the same:\nThese functions take the same JSON input arguments (String, IO, or filename for parsefile)\nThe dicttype, allownan, and null keyword arguments all remain and implement the same functionality\nWhat changed:\nJSON.Object{String, Any} is now the default type used when parsing instead of Dict{String, Any}; JSON.Object is a drop-in replacement for Dict, supporting the AbstractDict interface, mutation, dot-access (getproperty) to keys, memory and performance benefits for small objects vs. Dict, and preserves the JSON order of keys. For large objects (hundreds or thousands of keys), or to otherwise restore the pre-1.0 behavior, you can do JSON.parse(json; dicttype=Dict{String, Any}).\nThe inttype keyword argument has been removed\nThe allownan keyword argument now defaults to false instead of true to provide a more accurate JSON specification behavior as the default\nThe use_mmap keyword argument has been removed from parsefile; mmapping will now be decided automatically by the package and any mmaps used for parsing will be completely finalized when parsing has finished\nNumbers in JSON will now be parsed as Int64, BigInt, Float64, or BigFloat, instead of only Int64 or Float64. Many JSON libraries support arbitrary precision ints/floats, and now JSON.jl does too.\nJSON.parse(json, T) and JSON.parse!(json, x) variants have been added for constructing a Julia value from JSON, or mutating an existing Julia value from JSON; JSON.parsefile(json, T) and JSON.parsefile!(json, x) are also supported; see JSON Reading for more details\nWhy the changes:\nThe inttype keyword argument is rare among other JSON libraries and doesn't serve a strong purpose; memory gains from possibly using smaller ints is minimal and leads to more error-prone code via overflows by trying to force integers into non-standard small types\nFor the allownan default value change, there are many benchmarks/JSON-accuracy checking test suites that enforce adherance to the specification; following the specification by default is recommended and common across language JSON libraries\nMmapping is an internal detail that most users shouldn't worry about anyway, and it can be done transparently without any outside affect to the user\nJSONText\nJSONText can now also be used while parsing, as a field type of a struct or directly to return the raw JSON (similar to how writing with JSONText works)","category":"page"},{"location":"migrate/#Migration-guide-for-JSON3.jl","page":"Migration guides","title":"Migration guide for JSON3.jl","text":"","category":"section"},{"location":"migrate/","page":"Migration guides","title":"Migration guides","text":"The JSON.jl 1.0 release incorporates many of the design ideas that were originally developed in JSON3.jl. This guide helps you transition your code from JSON3.jl to JSON.jl 1.0, highlighting what's changed, what's similar, and the best way to update your code.","category":"page"},{"location":"migrate/#Writing-JSON-2","page":"Migration guides","title":"Writing JSON","text":"","category":"section"},{"location":"migrate/","page":"Migration guides","title":"Migration guides","text":"JSON3.write â†’ JSON.json\nWhat stayed the same:\nThe core functionality of serializing Julia values to JSON remains the same\nSupport for serializing custom structs in a sensible way\nBoth can output to a string or IO\nWhat changed:\nFunction name: JSON3.write becomes JSON.json\nDirect file writing: Instead of open(file, \"w\") do io; JSON3.write(io, x); end, you can use JSON.json(file, x)\nCustomization framework: JSON3.jl uses StructTypes.jl, while JSON.jl 1.0 uses StructUtils.jl\nPretty printing: JSON3.pretty(JSON3.write(x)) becomes JSON.json(x; pretty=true)\nSpecial numeric values: In JSON3.jl, writing NaN/Inf/-Inf required passing allow_inf=true, in JSON.jl 1.0 you pass allownan=true\nWhy the changes:\nPreference was given to existing JSON.jl names where possible (JSON.json, allownan, etc)\nJSON3 pretty printing support was an example of \"bolted on\" functionality that had a number of issues because it tried to operate on its own; in JSON.json, pretty printing is directly integrated with the core serializing code and thus doesn't suffer the same ergonomic problems\nStructUtils.jl is overall simpler and provides much more functionality \"by default\" meaning its much more invisible for majority of use-cases. Its design is the direct result of wanting to provide roughly similar functionality as StructTypes.jl but avoiding the pitfalls and architectural complexities it had\nCustom Type Serialization\nWhat stayed the same:\nBoth provide a way to customize how types are serialized\nBoth support serializing custom types to any valid JSON value\nWhat changed:\nInterface: No need to declare StructTypes.StructType explicitly on structs (StructUtils.jl can detect the vast majority of struct types automatically)\nNon-owned types: JSON.jl (via StructUtils) provides the concept of defining a custom StructStyle subtype that allows customizing the lowering/lifting overloads of non-owned types (JSON3.jl had repeated requests/issues with users wanting more control over non-owned types without pirating)\nWhy the changes:\nAs noted above, the overall design of StructUtils is simpler and more automatic, with the default definitions working in the vast majority of cases. If you're the author of a custom Number, AbstractString, AbstractArray, or AbstractDict, you may need to dig further into StructUtil machinery to make your types serialize/deserialize as expected, but regular structs should \"just work\"\nDefining custom styles is meant to balance having to do some extra work (defining the style, passing it to JSON.json/JSON.parse) with the power and flexibility of control over how JSON serialization/deserialization work for any type, owned or not\nField Customization\nWhat stayed the same:\nBoth allow renaming fields, excluding fields, and some control over manipulating fields from JSON output (keyword args, dateformats, etc.)\nWhat changed:\nStructUtils provides convenient \"struct\" macros (@noarg, @kwarg, @tags, @defaults, @nonstruct) that allow defining default values for fields, and specifying \"field tags\" which are named tuples of properties for fields. Via field tags, fields can customize naming, ignoring/excluding, dateformating, custom lowering/lifting, and even \"type choosing\" for abstract types.\nWhy the changes:\nThe field tags and defaults of StructUtils provide very powerful and generalized abilities to specify properties for fields. These are integrated directly with the serialize/deserialize process of StructUtils and provide a seemless way to enhance and control fields as desired. Instead of providing numerous StructType overloads, we can annotate individual fields appropriately, keeping context and information tidy and close to the source.\nNull and Empty Value Handling\nWhat stayed the same:\nBoth allow control over including/omitting null values and empty collections\nWhat changed:\nControl mechanism: JSON3.jl uses StructTypes.omitempties, JSON.jl 1.0 uses keyword arguments omit_null and omit_empty; or struct-level overloads or annotations to control omission","category":"page"},{"location":"migrate/#Reading-JSON-2","page":"Migration guides","title":"Reading JSON","text":"","category":"section"},{"location":"migrate/","page":"Migration guides","title":"Migration guides","text":"JSON3.read â†’ JSON.parse / JSON.lazy\nWhat stayed the same:\nCore functionality of parsing JSON into Julia values\nSupport for typed parsing into custom structs\nLazy parsing features\nWhat changed:\nFunction names: JSON3.read becomes either JSON.parse (eager) or JSON.lazy (lazy)\nDefault container type: JSON3.Object/JSON3.Array becomes JSON.Object{String, Any}/Vector{Any}\nType integration: JSON3.jl uses StructTypes.jl, JSON.jl 1.0 uses StructUtils.jl\nLazy value access: Both use property access syntax (obj.field) but with slightly different semantics\nMigration examples:\n# JSON3.jl\nobj = JSON3.read(json_str)\ntyped_obj = JSON3.read(json_str, MyType)\n\n# JSON.jl 1.0\nobj = JSON.parse(json_str)               # eager parsing\nlazy_obj = JSON.lazy(json_str)           # lazy parsing\nmaterialized = lazy_obj[]                # materialize lazy value\ntyped_obj = JSON.parse(json_str, MyType) # typed parsing\nLazy Parsing\nWhat stayed the same:\nBoth support lazy parsing for efficient access to parts of large JSON documents\nBoth allow dot notation for accessing object fields\nWhat changed:\nObject types: JSON3.Object becomes JSON.LazyValue with object type\nArray indexing: Similar, but slight syntax differences for materializing values\nMaterialization: In JSON3.jl specific values materialize when accessed, in JSON.jl 1.0 you explicitly use [] to materialize\nMigration examples:\n# JSON3.jl\nobj = JSON3.read(json_str)\nvalue = obj.deeply.nested.field  # value is materialized\n\n# JSON.jl 1.0\nobj = JSON.lazy(json_str)\nlazy_value = obj.deeply.nested.field  # still lazy\nvalue = obj.deeply.nested.field[]     # now materialized\nWhy the changes:\nThe lazy support in JSON.jl is truly lazy and the underlying JSON is only parsed/navigated as explicitly requested. JSON3.jl still fully parsed the JSON into a fairly compact binary representation, avoiding full materialization of objects and arrays.\nTyped Parsing\nWhat stayed the same:\nBoth allow parsing directly into custom types\nBoth support object mapping, handling nested types, unions with Nothing/Missing\nWhat changed:\nInterface: StructTypes.StructType becomes JSON.jl's StructUtils integration\nDefault values: StructTypes.defaults becomes @defaults macro\nType selection: Custom JSON3 dispatching becomes JSON.@choosetype\nMigration examples:\n# JSON3.jl\nStructTypes.StructType(::Type{MyType}) = StructTypes.Struct()\nStructTypes.defaults(::Type{MyType}) = (field1=0, field2=\"default\")\n\n# Type selection in JSON3.jl\nStructTypes.StructType(::Type{AbstractParent}) = StructTypes.AbstractType()\nStructTypes.subtypes(::Type{AbstractParent}) = (a=ConcreteA, b=ConcreteB)\n\n# JSON.jl 1.0\n@defaults struct MyType\n    field1::Int = 0\n    field2::String = \"default\"\nend\n\n# Type selection in JSON.jl 1.0\nJSON.@choosetype AbstractParent x -> x.type[] == \"a\" ? ConcreteA : ConcreteB\nCustom Field Mapping\nWhat stayed the same:\nBoth support mapping between JSON property names and struct field names\nBoth handle date formatting and other special types\nWhat changed:\nInterface: JSON3.jl uses StructTypes.names, JSON.jl 1.0 uses field tags\nDate handling: Different formats for specifying date formats\nMigration examples:\n# JSON3.jl\nStructTypes.names(::Type{MyType}) = ((:json_name, :struct_field),)\nStructTypes.keywordargs(::Type{MyType}) = (date_field=(dateformat=dateformat\"yyyy-mm-dd\",),)\n\n# JSON.jl 1.0\n@tags struct MyType\n    struct_field::Int &(json=(name=\"json_name\",),)\n    date_field::Date &(json=(dateformat=\"yyyy-mm-dd\",),)\nend","category":"page"},{"location":"migrate/#Features-unique-to-each-library","page":"Migration guides","title":"Features unique to each library","text":"","category":"section"},{"location":"migrate/","page":"Migration guides","title":"Migration guides","text":"Only in JSON3.jl:\nStruct Generation: The ability to automatically generate Julia struct definitions from JSON examples\n# This functionality is not available in JSON.jl 1.0\nstruct_def = JSON3.generate_struct(json_data, \"MyStruct\")\nIf you rely heavily on this feature, continue using JSON3.jl for this specific purpose until this functionality is migrated to a separate package\nOnly in JSON.jl 1.0:\nEnhanced JSON Lines Support: Better handling of JSON Lines format with auto-detection for files with .jsonl extension\nMore Float Formatting Controls: Additional options for float precision and format style\nImproved Circular Reference Handling: Better detection and handling of circular references","category":"page"},{"location":"reference/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"reference/","page":"API Reference","title":"API Reference","text":"","category":"page"},{"location":"reference/#JSON.JSONText","page":"API Reference","title":"JSON.JSONText","text":"JSON.JSONText\n\nWrapper around a string containing JSON data. Can be used to insert raw JSON in JSON output, like:\n\njson(JSONText(\"{\"key\": \"value\"}\"))\n\nThis will output the JSON as-is, without escaping. Note that no check is done to ensure that the JSON is valid.\n\nCan also be used to read \"raw JSON\" when parsing, meaning no specialized structure (JSON.Object, Vector{Any}, etc.) is created. Example:\n\nx = JSON.parse(\"[1,2,3]\", JSONText)\n# x.value == \"[1,2,3]\"\n\n\n\n\n\n","category":"type"},{"location":"reference/#JSON.LazyValue","page":"API Reference","title":"JSON.LazyValue","text":"JSON.LazyValue\n\nA lazy representation of a JSON value. The LazyValue type supports the \"selection\" syntax for lazily navigating the JSON value. Lazy values can be materialized via JSON.parse(x), JSON.parse(x, T), or JSON.parse!(x, y).\n\n\n\n\n\n","category":"type"},{"location":"reference/#JSON.isvalidjson","page":"API Reference","title":"JSON.isvalidjson","text":"JSON.isvalidjson(json) -> Bool\n\nCheck if the given JSON is valid. This function will return true if the JSON is valid, and false otherwise. Inputs can be a string, a vector of bytes, or an IO stream, the same inputs as supported for JSON.lazy and JSON.parse.\n\n\n\n\n\n","category":"function"},{"location":"reference/#JSON.json","page":"API Reference","title":"JSON.json","text":"JSON.json(x) -> String\nJSON.json(io, x)\nJSON.json(file_name, x)\n\nSerialize x to JSON format. The 1st method takes just the object and returns a String. In the 2nd method, io is an IO object, and the JSON output will be written to it. For the 3rd method, file_name is a String, a file will be opened and the JSON output will be written to it.\n\nAll methods accept the following keyword arguments:\n\nomit_null::Union{Bool, Nothing}=nothing: Controls whether struct fields that are undefined or are nothing are included in the JSON output. If true, only non-null fields are written. If false, all fields are included regardless of being undefined or nothing. If nothing, the behavior is determined by JSON.omit_null(::Type{T}), which is false by default.\nomit_empty::Union{Bool, Nothing}=nothing: Controls whether struct fields that are empty are included in the JSON output. If true, empty fields are excluded. If false, empty fields are included. If nothing, the behavior is determined by JSON.omit_empty(::Type{T}).\nallownan::Bool=false: If true, allow Inf, -Inf, and NaN in the output. If false, throw an error if Inf, -Inf, or NaN is encountered.\njsonlines::Bool=false: If true, input must be array-like and the output will be written in the JSON Lines format, where each element of the array is written on a separate line (i.e. separated by a single newline character `\n\n).   Iffalse`, the output will be written in the standard JSON format.\n\npretty::Union{Integer,Bool}=false: Controls pretty printing of the JSON output. If true, the output will be pretty-printed with 2 spaces of indentation. If an integer, it will be used as the number of spaces of indentation. If false or 0, the output will be compact. Note: Pretty printing is not supported when jsonlines=true.\ninline_limit::Int=0: For arrays shorter than this limit, pretty printing will be disabled (indentation set to 0).\nninf::String=\"-Infinity\": Custom string representation for negative infinity.\ninf::String=\"Infinity\": Custom string representation for positive infinity.\nnan::String=\"NaN\": Custom string representation for NaN.\nfloat_style::Symbol=:shortest: Controls how floating-point numbers are formatted. Options are:\n:shortest: Use the shortest representation that preserves the value\n:fixed: Use fixed-point notation\n:exp: Use exponential notation\nfloat_precision::Int=1: Number of decimal places to use when float_style is :fixed or :exp.\nbufsize::Int=2^22: Buffer size in bytes for IO operations. When writing to IO, the buffer will be flushed  to the IO stream once it reaches this size. This helps control memory usage during large write operations. Default is 4MB (2^22 bytes). This parameter is ignored when returning a String.\nstyle::JSONStyle=JSONWriteStyle(): Custom style object that controls serialization behavior. This allows customizing   certain aspects of serialization, like defining a custom lower method for a non-owned type. Like struct MyStyle <: JSONStyle end,   JSON.lower(x::Rational) = (num=x.num, den=x.den), then calling JSON.json(1//3; style=MyStyle()) will output   {\"num\": 1, \"den\": 3}.\n\nBy default, x must be a JSON-serializable object. Supported types include:\n\nAbstractString => JSON string: types must support the AbstractString interface, specifically with support for ncodeunits and codeunit(x, i).\nBool => JSON boolean: must be true or false\nNothing => JSON null: must be the nothing singleton value\nNumber => JSON number: Integer subtypes or Union{Float16, Float32, Float64} have default implementations for other Number types, JSON.tostring is first called to convert the value to a String before being written directly to JSON output\nAbstractArray/Tuple/AbstractSet => JSON array: objects for which JSON.arraylike returns true  are output as JSON arrays. arraylike is defined by default for AbstractArray, AbstractSet, Tuple, and Base.Generator. For other types that define, they must also properly implement StructUtils.applyeach to iterate over the index => elements pairs. Note that arrays with dimensionality > 1 are written as nested arrays, with N nestings for N dimensions, and the 1st dimension is always the innermost nested JSON array (column-major order).\nAbstractDict/NamedTuple/structs => JSON object: if a value doesn't fall into any of the above categories, it is output as a JSON object. StructUtils.applyeach is called, which has appropriate implementations for AbstractDict, NamedTuple, and structs, where field names => values are iterated over. Field names can be output with an alternative name via field tag overload, like field::Type &(json=(name=\"alternative_name\",),)\n\nIf an object is not JSON-serializable, an override for JSON.lower can be defined to convert it to a JSON-serializable object. Some default lower defintions are defined in JSON itself, for example:\n\nStructUtils.lower(::Missing) = nothing\nStructUtils.lower(x::Symbol) = String(x)\nStructUtils.lower(x::Union{Enum, AbstractChar, VersionNumber, Cstring, Cwstring, UUID, Dates.TimeType}) = string(x)\nStructUtils.lower(x::Regex) = x.pattern\n\nThese allow common Base/stdlib types to be serialized in an expected format.\n\nCircular references are tracked automatically and cycles are broken by writing null for any children references.\n\nFor pre-formatted JSON data as a String, use JSONText(json) to write the string out as-is.\n\nFor AbstractDict objects with non-string keys, StructUtils.lowerkey will be called before serializing. This allows aggregate or other types of dict keys to be converted to an appropriate string representation. See StructUtils.liftkey for the reverse operation, which is called when parsing JSON data back into a dict type.\n\nNOTE: JSON.json should not be overloaded directly by custom types as this isn't robust for various output options (IO, String, etc.) nor recursive situations. Types should define an appropriate JSON.lower definition instead.\n\nNOTE: JSON.json(str, indent::Integer) is special-cased for backwards compatibility with pre-1.0 JSON.jl, as this typically would mean \"write out the indent integer to file str\". As writing out a single integer to a file is extremely rare, it was decided to keep the pre-1.0 behavior for compatibility reasons.\n\nExamples:\n\nusing Dates\n\nabstract type AbstractMonster end\n\nstruct Dracula <: AbstractMonster\n    num_victims::Int\nend\n\nstruct Werewolf <: AbstractMonster\n    witching_hour::DateTime\nend\n\nstruct Percent <: Number\n    value::Float64\nend\n\nJSON.lower(x::Percent) = x.value\nStructUtils.lowerkey(x::Percent) = string(x.value)\n\n@noarg mutable struct FrankenStruct\n    id::Int\n    name::String # no default to show serialization of an undefined field\n    address::Union{Nothing, String} = nothing\n    rate::Union{Missing, Float64} = missing\n    type::Symbol = :a &(json=(name=\"franken_type\",),)\n    notsure::Any = JSON.Object(\"key\" => \"value\")\n    monster::AbstractMonster = Dracula(10) &(json=(lower=x -> x isa Dracula ? (monster_type=\"vampire\", num_victims=x.num_victims) : (monster_type=\"werewolf\", witching_hour=x.witching_hour),),)\n    percent::Percent = Percent(0.5)\n    birthdate::Date = Date(2025, 1, 1) &(json=(dateformat=\"yyyy/mm/dd\",),)\n    percentages::Dict{Percent, Int} = Dict{Percent, Int}(Percent(0.0) => 0, Percent(1.0) => 1)\n    json_properties::JSONText = JSONText(\"{\"key\": \"value\"}\")\n    matrix::Matrix{Float64} = [1.0 2.0; 3.0 4.0]\n    extra_field::Any = nothing &(json=(ignore=true,),)\nend\n\nfranken = FrankenStruct()\nfranken.id = 1\n\njson = JSON.json(franken; omit_null=false)\n# \"{\"id\":1,\"name\":null,\"address\":null,\"rate\":null,\"franken_type\":\"a\",\"notsure\":{\"key\":\"value\"},\"monster\":{\"monster_type\":\"vampire\",\"num_victims\":10},\"percent\":0.5,\"birthdate\":\"2025/01/01\",\"percentages\":{\"1.0\":1,\"0.0\":0},\"json_properties\":{\"key\": \"value\"},\"matrix\":[[1.0,3.0],[2.0,4.0]]}\"\n\nA few comments on the JSON produced in the example above:\n\nThe name field was #undef, and thus was serialized as null.\nThe address and rate fields were nothing and missing, respectively, and thus were serialized as null.\nThe type field has a name field tag, so the JSON key for this field is franken_type instead of type.\nThe notsure field is a JSON.Object, so it is serialized as a JSON object.\nThe monster field is a AbstractMonster, which is a custom type. It has a lower field tag that specifies how the value of this field specifically (not all AbstractMonster) should be serialized\nThe percent field is a Percent, which is a custom type. It has a lower method that specifies how Percent values should be serialized\nThe birthdate field has a dateformat field tag, so the value follows the format (yyyy/mm/dd) instead of the default date ISO format (yyyy-mm-dd)\nThe percentages field is a Dict{Percent, Int}, which is a custom type. It has a lowerkey method that specifies how Percent keys should be serialized as strings\nThe json_properties field is a JSONText, so the JSONText value is serialized as-is\nThe matrix field is a Matrix{Float64}, which is a custom type. It is serialized as a JSON array, with the first dimension being the innermost nested JSON array (column-major order)\nThe extra_field field has a ignore field tag, so it is skipped when serializing\n\n\n\n\n\n","category":"function"},{"location":"reference/#JSON.lazy","page":"API Reference","title":"JSON.lazy","text":"JSON.lazy(json; kw...)\nJSON.lazyfile(file; kw...)\n\nDetect the initial JSON value in json, returning a JSON.LazyValue instance. json input can be:\n\nAbstractString\nAbstractVector{UInt8}\nIO, IOStream, Cmd (bytes are fully read into a Vector{UInt8} for parsing, i.e. read(json) is called)\n\nlazyfile is a convenience method that takes a filename and opens the file before calling lazy.\n\nThe JSON.LazyValue supports the \"selection\" syntax for lazily navigating the JSON value. For example (x = JSON.lazy(json)):\n\nx.key, x[:key] or x[\"key\"] for JSON objects\nx[1], x[2:3], x[end] for JSON arrays\npropertynames(x) to see all keys in the JSON object\nx.a.b.c for selecting deeply nested values\nx[~, (k, v) -> k == \"foo\"] for recursively searching for key \"foo\" and return matching values\n\nNOTE: Selecting values from a LazyValue will always return a LazyValue. Selecting a specific key of an object or index of an array will only parse what is necessary before returning. This leads to a few conclusions about how to effectively utilize LazyValue:\n\nJSON.lazy is great for one-time access of a value in JSON\nIt's also great for finding a required deeply nested value\nIt's not great for any case where repeated access to values is required; this results in the same JSON being parsed on each access (i.e. naively iterating a lazy JSON array will be O(n^2))\nBest practice is to use JSON.lazy sparingly unless there's a specific case where it will benefit; or use JSON.lazy as a means to access a value that is then fully materialized\n\nAnother option for processing JSON.LazyValue is calling foreach(f, x) which is defined on JSON.LazyValue for JSON objects and arrays. For objects, f should be of the form f(kv::Pair{String, LazyValue}) where kv is a key-value pair, and for arrays, f(v::LazyValue) where v is the value at the index. This allows for iterating over all key-value pairs in an object or all values in an array without materializing the entire structure.\n\nLazy values can be materialized via JSON.parse in a few different forms:\n\nJSON.parse(json): Default materialization into JSON.Object (a Dict-like type), Vector{Any}, etc.\nJSON.parse(json, T): Materialize into a user-provided type T (following rules/programmatic construction from StructUtils.jl)\nJSON.parse!(json, x): Materialize into an existing object x (following rules/programmatic construction from StructUtils.jl)\n\nThus for completeness sake, here's an example of ideal usage of JSON.lazy:\n\nx = JSON.lazy(very_large_json_object)\n# find a deeply nested value\ny = x.a.b.c.d.e.f.g\n# materialize the value\nz = JSON.parse(y)\n# now mutate/repeatedly access values in z\n\nIn this example, we only parsed as much of the very_large_json_object as was required to find the value y. Then we fully materialized y into z, which is now a normal Julia object. We can now mutate or access values in z.\n\nCurrently supported keyword arguments include:\n\nallownan::Bool = false: whether \"special\" float values shoudl be allowed while parsing (NaN, Inf, -Inf); these values are specifically not allowed in the JSON spec, but many JSON libraries allow reading/writing\nninf::String = \"-Infinity\": the string that will be used to parse -Inf if allownan=true\ninf::String = \"Infinity\": the string that will be used to parse Inf if allownan=true\nnan::String = \"NaN\": the string that will be sued to parse NaN if allownan=true\njsonlines::Bool = false: whether the JSON input should be treated as an implicit array, with newlines separating individual JSON elements with no leading '[' or trailing ']' characters. Common in logging or streaming workflows. Defaults to true when used with JSON.parsefile and the filename extension is .jsonl or ndjson. Note this ensures that parsing will always return an array at the root-level.\n\nNote that validation is only fully done on null, true, and false, while other values are only lazily inferred from the first non-whitespace character:\n\n'{': JSON object\n'[': JSON array\n'\"': JSON string\n'0'-'9' or '-': JSON number\n\nFurther validation for these values is done later when materialized, like JSON.parse, or via selection syntax calls on a LazyValue.\n\n\n\n\n\n","category":"function"},{"location":"reference/#JSON.lazyfile","page":"API Reference","title":"JSON.lazyfile","text":"JSON.lazy(json; kw...)\nJSON.lazyfile(file; kw...)\n\nDetect the initial JSON value in json, returning a JSON.LazyValue instance. json input can be:\n\nAbstractString\nAbstractVector{UInt8}\nIO, IOStream, Cmd (bytes are fully read into a Vector{UInt8} for parsing, i.e. read(json) is called)\n\nlazyfile is a convenience method that takes a filename and opens the file before calling lazy.\n\nThe JSON.LazyValue supports the \"selection\" syntax for lazily navigating the JSON value. For example (x = JSON.lazy(json)):\n\nx.key, x[:key] or x[\"key\"] for JSON objects\nx[1], x[2:3], x[end] for JSON arrays\npropertynames(x) to see all keys in the JSON object\nx.a.b.c for selecting deeply nested values\nx[~, (k, v) -> k == \"foo\"] for recursively searching for key \"foo\" and return matching values\n\nNOTE: Selecting values from a LazyValue will always return a LazyValue. Selecting a specific key of an object or index of an array will only parse what is necessary before returning. This leads to a few conclusions about how to effectively utilize LazyValue:\n\nJSON.lazy is great for one-time access of a value in JSON\nIt's also great for finding a required deeply nested value\nIt's not great for any case where repeated access to values is required; this results in the same JSON being parsed on each access (i.e. naively iterating a lazy JSON array will be O(n^2))\nBest practice is to use JSON.lazy sparingly unless there's a specific case where it will benefit; or use JSON.lazy as a means to access a value that is then fully materialized\n\nAnother option for processing JSON.LazyValue is calling foreach(f, x) which is defined on JSON.LazyValue for JSON objects and arrays. For objects, f should be of the form f(kv::Pair{String, LazyValue}) where kv is a key-value pair, and for arrays, f(v::LazyValue) where v is the value at the index. This allows for iterating over all key-value pairs in an object or all values in an array without materializing the entire structure.\n\nLazy values can be materialized via JSON.parse in a few different forms:\n\nJSON.parse(json): Default materialization into JSON.Object (a Dict-like type), Vector{Any}, etc.\nJSON.parse(json, T): Materialize into a user-provided type T (following rules/programmatic construction from StructUtils.jl)\nJSON.parse!(json, x): Materialize into an existing object x (following rules/programmatic construction from StructUtils.jl)\n\nThus for completeness sake, here's an example of ideal usage of JSON.lazy:\n\nx = JSON.lazy(very_large_json_object)\n# find a deeply nested value\ny = x.a.b.c.d.e.f.g\n# materialize the value\nz = JSON.parse(y)\n# now mutate/repeatedly access values in z\n\nIn this example, we only parsed as much of the very_large_json_object as was required to find the value y. Then we fully materialized y into z, which is now a normal Julia object. We can now mutate or access values in z.\n\nCurrently supported keyword arguments include:\n\nallownan::Bool = false: whether \"special\" float values shoudl be allowed while parsing (NaN, Inf, -Inf); these values are specifically not allowed in the JSON spec, but many JSON libraries allow reading/writing\nninf::String = \"-Infinity\": the string that will be used to parse -Inf if allownan=true\ninf::String = \"Infinity\": the string that will be used to parse Inf if allownan=true\nnan::String = \"NaN\": the string that will be sued to parse NaN if allownan=true\njsonlines::Bool = false: whether the JSON input should be treated as an implicit array, with newlines separating individual JSON elements with no leading '[' or trailing ']' characters. Common in logging or streaming workflows. Defaults to true when used with JSON.parsefile and the filename extension is .jsonl or ndjson. Note this ensures that parsing will always return an array at the root-level.\n\nNote that validation is only fully done on null, true, and false, while other values are only lazily inferred from the first non-whitespace character:\n\n'{': JSON object\n'[': JSON array\n'\"': JSON string\n'0'-'9' or '-': JSON number\n\nFurther validation for these values is done later when materialized, like JSON.parse, or via selection syntax calls on a LazyValue.\n\n\n\n\n\n","category":"function"},{"location":"reference/#JSON.omit_empty-Union{Tuple{Type{T}}, Tuple{T}} where T","page":"API Reference","title":"JSON.omit_empty","text":"JSON.omit_empty(::Type{T})::Bool\nJSON.omit_empty(::JSONStyle, ::Type{T})::Bool\n\nControls whether struct fields that are empty are included in the JSON output. Returns false by default, meaning empty fields are included. To instead exclude empty fields, set this to true. A field is considered empty if it is nothing, an empty collection (empty array, dict, string, tuple, or named tuple), or missing. This can also be controlled via the omit_empty keyword argument in JSON.json.\n\n# Override for a specific type\nJSON.omit_empty(::Type{MyStruct}) = true\n\n# Override for a custom style\nstruct MyStyle <: JSON.JSONStyle end\nJSON.omit_empty(::MyStyle, ::Type{T}) where {T} = true\n\n\n\n\n\n","category":"method"},{"location":"reference/#JSON.omit_null-Union{Tuple{Type{T}}, Tuple{T}} where T","page":"API Reference","title":"JSON.omit_null","text":"JSON.omit_null(::Type{T})::Bool\nJSON.omit_null(::JSONStyle, ::Type{T})::Bool\n\nControls whether struct fields that are undefined or are nothing are included in the JSON output. Returns false by default, meaning all fields are included, regardless of undef or nothing. To instead ensure only non-null fields are written, set this to true. This can also be controlled via the omit_null keyword argument in JSON.json.\n\n# Override for a specific type\nJSON.omit_null(::Type{MyStruct}) = true\n\n# Override for a custom style\nstruct MyStyle <: JSON.JSONStyle end\nJSON.omit_null(::MyStyle, ::Type{T}) where {T} = true\n\n\n\n\n\n","category":"method"},{"location":"reference/#JSON.parse","page":"API Reference","title":"JSON.parse","text":"JSON.parse(json)\nJSON.parse(json, T)\nJSON.parse!(json, x)\nJSON.parsefile(filename)\nJSON.parsefile(filename, T)\nJSON.parsefile!(filename, x)\n\nParse a JSON input (string, vector, stream, LazyValue, etc.) into a Julia value. The parsefile variants take a filename, open the file, and pass the IOStream to parse.\n\nCurrently supported keyword arguments include:\n\nallownan: allows parsing NaN, Inf, and -Inf since they are otherwise invalid JSON\nninf: string to use for -Inf (default: \"-Infinity\")\ninf: string to use for Inf (default: \"Infinity\")\nnan: string to use for NaN (default: \"NaN\")\njsonlines: treat the json input as an implicit JSON array, delimited by newlines, each element being parsed from each row/line in the input\ndicttype: a custom AbstractDict type to use instead of JSON.Object{String, Any} as the default type for JSON object materialization\nnull: a custom value to use for JSON null values (default: nothing)\nstyle: a custom StructUtils.StructStyle subtype instance to be used in calls to StructUtils.make and StructUtils.lift. This allows overriding default behaviors for non-owned types.\n\nThe methods without a type specified (JSON.parse(json), JSON.parsefile(filename)), do a generic materialization into predefined default types, including:\n\nJSON object => JSON.Object{String, Any} (see note below)\nJSON array => Vector{Any}\nJSON string => String\nJSON number => Int64, BigInt, Float64, or BigFloat\nJSON true => true\nJSON false => false\nJSON null => nothing\n\nWhen a type T is specified (JSON.parse(json, T), JSON.parsefile(filename, T)), materialization to a value of type T will be attempted utilizing machinery and interfaces provided by the StructUtils.jl package, including:\n\nFor JSON objects, JSON keys will be matched against field names of T with a value being constructed via T(args...)\nIf T was defined with the @noarg macro, an empty instance will be constructed, and field values set as JSON keys match field names\nIf T had default field values defined using the @defaults or @kwarg macros (from StructUtils.jl package), those will be set in the value of T unless different values are parsed from the JSON\nIf T was defined with the @nonstruct macro, the struct will be treated as a primitive type and constructed using the lift function rather than from field values\nJSON keys that don't match field names in T will be ignored (skipped over)\nIf a field in T has a name fieldtag, the name value will be used to match JSON keys instead\nIf T or any recursive field type of T is abstract, an appropriate JSON.@choosetype T x -> ... definition should exist for \"choosing\" a concrete type at runtime; default type choosing exists for Union{T, Missing} and Union{T, Nothing} where the JSON value is checked if null. If the Any type is encountered, the default materialization types will be used (JSON.Object, Vector{Any}, etc.)\nFor any non-JSON-standard non-aggregate (i.e. non-object, non-array) field type of T, a JSON.lift(::Type{T}, x) = ... definition can be defined for how to \"lift\" the default JSON value (String, Number, Bool, nothing) to the type T; a default lift definition exists, for example, for JSON.lift(::Type{Missing}, x) = missing where the standard JSON value for null is nothing and it can be \"lifted\" to missing\nFor any T or recursive field type of T that is AbstractDict, non-string/symbol/integer keys will need to have a StructUtils.liftkey(::Type{T}, x)) definition for how to \"lift\" the JSON string key to the key type of T\n\nFor any T or recursive field type of T that is JSON.JSONText, the next full raw JSON value will be preserved in the JSONText wrapper as-is.\n\nFor the unique case of nested JSON arrays and prior knowledge of the expected dimensionality, a target type T can be given as an AbstractArray{T, N} subtype. In this case, the JSON array data is materialized as an n-dimensional array, where: the number of JSON array nestings must match the Julia array dimensionality (N), nested JSON arrays at matching depths are assumed to have equal lengths, and the length of the innermost JSON array is the 1st dimension length and so on. For example, the JSON array [[[1.0,2.0]]] would be materialized as a 3-dimensional array of Float64 with sizes (2, 1, 1), when called like JSON.parse(\"[[[1.0,2.0]]]\", Array{Float64, 3}). Note that n-dimensional Julia arrays are written to json as nested JSON arrays by default, to enable lossless re-parsing, though the dimensionality must still be provided explicitly to the call to parse (i.e. default parsing via JSON.parse(json) will result in plain nested Vector{Any}s returned).\n\nExamples:\n\nusing Dates\n\nabstract type AbstractMonster end\n\nstruct Dracula <: AbstractMonster\n    num_victims::Int\nend\n\nstruct Werewolf <: AbstractMonster\n    witching_hour::DateTime\nend\n\nJSON.@choosetype AbstractMonster x -> x.monster_type[] == \"vampire\" ? Dracula : Werewolf\n\nstruct Percent <: Number\n    value::Float64\nend\n\nJSON.lift(::Type{Percent}, x) = Percent(Float64(x))\nStructUtils.liftkey(::Type{Percent}, x::String) = Percent(parse(Float64, x))\n\n@defaults struct FrankenStruct\n    id::Int = 0\n    name::String = \"Jim\"\n    address::Union{Nothing, String} = nothing\n    rate::Union{Missing, Float64} = missing\n    type::Symbol = :a &(json=(name=\"franken_type\",),)\n    notsure::Any = nothing\n    monster::AbstractMonster = Dracula(0)\n    percent::Percent = Percent(0.0)\n    birthdate::Date = Date(0) &(json=(dateformat=\"yyyy/mm/dd\",),)\n    percentages::Dict{Percent, Int} = Dict{Percent, Int}()\n    json_properties::JSONText = JSONText(\"\")\n    matrix::Matrix{Float64} = Matrix{Float64}(undef, 0, 0)\nend\n\njson = \"\"\"\n{\n    \"id\": 1,\n    \"address\": \"123 Main St\",\n    \"rate\": null,\n    \"franken_type\": \"b\",\n    \"notsure\": {\"key\": \"value\"},\n    \"monster\": {\n        \"monster_type\": \"vampire\",\n        \"num_victims\": 10\n    },\n    \"percent\": 0.1,\n    \"birthdate\": \"2023/10/01\",\n    \"percentages\": {\n        \"0.1\": 1,\n        \"0.2\": 2\n    },\n    \"json_properties\": {\"key\": \"value\"},\n    \"matrix\": [[1.0, 2.0], [3.0, 4.0]],\n    \"extra_key\": \"extra_value\"\n}\n\"\"\"\nJSON.parse(json, FrankenStruct)\n# FrankenStruct(1, \"Jim\", \"123 Main St\", missing, :b, JSON.Object{String, Any}(\"key\" => \"value\"), Dracula(10), Percent(0.1), Date(\"2023-10-01\"), Dict{Percent, Int64}(Percent(0.2) => 2, Percent(0.1) => 1), JSONText(\"{\"key\": \"value\"}\"), [1.0 3.0; 2.0 4.0])\n\nLet's walk through some notable features of the example above:\n\nThe name field isn't present in the JSON input, so the default value of \"Jim\" is used.\nThe address field uses a default @choosetype to determine that the JSON value is not null, so a String should be parsed for the field value.\nThe rate field has a null JSON value, so the default @choosetype recognizes it should be \"lifted\" to Missing, which then uses a predefined lift definition for Missing.\nThe type field is a Symbol, and has a fieldtag json=(name=\"franken_type\",) which means the JSON key franken_type will be used to set the field value instead of the default type field name. A default lift definition for Symbol is used to convert the JSON string value to a Symbol.\nThe notsure field is of type Any, so the default object type JSON.Object{String, Any} is used to materialize the JSON value.\nThe monster field is a polymorphic type, and the JSON value has a monster_type key that determines which concrete type to use. The @choosetype macro is used to define the logic for choosing the concrete type based on the JSON input. Note that teh x in @choosetype is a LazyValue, so we materialize via x.monster_type[] in order to compare with the string \"vampire\".\nThe percent field is a custom type Percent and the JSON.lift defines how to construct a Percent from the JSON value, which is a Float64 in this case.\nThe birthdate field uses a custom date format for parsing, specified in the JSON input.\nThe percentages field is a dictionary with keys of type Percent, which is a custom type. The liftkey function is defined to convert the JSON string keys to Percent types (parses the Float64 manually)\nThe json_properties field has a type of JSONText, which means the raw JSON will be preserved as a String of the JSONText type.\nThe matrix field is a Matrix{Float64}, so the JSON input array-of-arrays are materialized as such.\nThe extra_key field is not defined in the FrankenStruct type, so it is ignored and skipped over.\n\nNOTE: Why use JSON.Object{String, Any} as the default object type? It provides several benefits:\n\nBehaves as a drop-in replacement for Dict{String, Any}, so no loss of functionality\nPerformance! It's internal representation means memory savings and faster construction for small objects typical in JSON (vs Dict)\nInsertion order is preserved, so the order of keys in the JSON input is preserved in JSON.Object\nConvenient getproperty (i.e. obj.key) syntax is supported, even for Object{String,Any} key types (again ideal/specialized for JSON usage)\n\nJSON.Object internal representation uses a linked list, thus key lookups are linear time (O(n)). For large JSON objects, (hundreds or thousands of keys), consider using a Dict{String, Any} instead, like JSON.parse(json; dicttype=Dict{String, Any}).\n\n\n\n\n\n","category":"function"},{"location":"reference/#JSON.parsefile","page":"API Reference","title":"JSON.parsefile","text":"JSON.parse(json)\nJSON.parse(json, T)\nJSON.parse!(json, x)\nJSON.parsefile(filename)\nJSON.parsefile(filename, T)\nJSON.parsefile!(filename, x)\n\nParse a JSON input (string, vector, stream, LazyValue, etc.) into a Julia value. The parsefile variants take a filename, open the file, and pass the IOStream to parse.\n\nCurrently supported keyword arguments include:\n\nallownan: allows parsing NaN, Inf, and -Inf since they are otherwise invalid JSON\nninf: string to use for -Inf (default: \"-Infinity\")\ninf: string to use for Inf (default: \"Infinity\")\nnan: string to use for NaN (default: \"NaN\")\njsonlines: treat the json input as an implicit JSON array, delimited by newlines, each element being parsed from each row/line in the input\ndicttype: a custom AbstractDict type to use instead of JSON.Object{String, Any} as the default type for JSON object materialization\nnull: a custom value to use for JSON null values (default: nothing)\nstyle: a custom StructUtils.StructStyle subtype instance to be used in calls to StructUtils.make and StructUtils.lift. This allows overriding default behaviors for non-owned types.\n\nThe methods without a type specified (JSON.parse(json), JSON.parsefile(filename)), do a generic materialization into predefined default types, including:\n\nJSON object => JSON.Object{String, Any} (see note below)\nJSON array => Vector{Any}\nJSON string => String\nJSON number => Int64, BigInt, Float64, or BigFloat\nJSON true => true\nJSON false => false\nJSON null => nothing\n\nWhen a type T is specified (JSON.parse(json, T), JSON.parsefile(filename, T)), materialization to a value of type T will be attempted utilizing machinery and interfaces provided by the StructUtils.jl package, including:\n\nFor JSON objects, JSON keys will be matched against field names of T with a value being constructed via T(args...)\nIf T was defined with the @noarg macro, an empty instance will be constructed, and field values set as JSON keys match field names\nIf T had default field values defined using the @defaults or @kwarg macros (from StructUtils.jl package), those will be set in the value of T unless different values are parsed from the JSON\nIf T was defined with the @nonstruct macro, the struct will be treated as a primitive type and constructed using the lift function rather than from field values\nJSON keys that don't match field names in T will be ignored (skipped over)\nIf a field in T has a name fieldtag, the name value will be used to match JSON keys instead\nIf T or any recursive field type of T is abstract, an appropriate JSON.@choosetype T x -> ... definition should exist for \"choosing\" a concrete type at runtime; default type choosing exists for Union{T, Missing} and Union{T, Nothing} where the JSON value is checked if null. If the Any type is encountered, the default materialization types will be used (JSON.Object, Vector{Any}, etc.)\nFor any non-JSON-standard non-aggregate (i.e. non-object, non-array) field type of T, a JSON.lift(::Type{T}, x) = ... definition can be defined for how to \"lift\" the default JSON value (String, Number, Bool, nothing) to the type T; a default lift definition exists, for example, for JSON.lift(::Type{Missing}, x) = missing where the standard JSON value for null is nothing and it can be \"lifted\" to missing\nFor any T or recursive field type of T that is AbstractDict, non-string/symbol/integer keys will need to have a StructUtils.liftkey(::Type{T}, x)) definition for how to \"lift\" the JSON string key to the key type of T\n\nFor any T or recursive field type of T that is JSON.JSONText, the next full raw JSON value will be preserved in the JSONText wrapper as-is.\n\nFor the unique case of nested JSON arrays and prior knowledge of the expected dimensionality, a target type T can be given as an AbstractArray{T, N} subtype. In this case, the JSON array data is materialized as an n-dimensional array, where: the number of JSON array nestings must match the Julia array dimensionality (N), nested JSON arrays at matching depths are assumed to have equal lengths, and the length of the innermost JSON array is the 1st dimension length and so on. For example, the JSON array [[[1.0,2.0]]] would be materialized as a 3-dimensional array of Float64 with sizes (2, 1, 1), when called like JSON.parse(\"[[[1.0,2.0]]]\", Array{Float64, 3}). Note that n-dimensional Julia arrays are written to json as nested JSON arrays by default, to enable lossless re-parsing, though the dimensionality must still be provided explicitly to the call to parse (i.e. default parsing via JSON.parse(json) will result in plain nested Vector{Any}s returned).\n\nExamples:\n\nusing Dates\n\nabstract type AbstractMonster end\n\nstruct Dracula <: AbstractMonster\n    num_victims::Int\nend\n\nstruct Werewolf <: AbstractMonster\n    witching_hour::DateTime\nend\n\nJSON.@choosetype AbstractMonster x -> x.monster_type[] == \"vampire\" ? Dracula : Werewolf\n\nstruct Percent <: Number\n    value::Float64\nend\n\nJSON.lift(::Type{Percent}, x) = Percent(Float64(x))\nStructUtils.liftkey(::Type{Percent}, x::String) = Percent(parse(Float64, x))\n\n@defaults struct FrankenStruct\n    id::Int = 0\n    name::String = \"Jim\"\n    address::Union{Nothing, String} = nothing\n    rate::Union{Missing, Float64} = missing\n    type::Symbol = :a &(json=(name=\"franken_type\",),)\n    notsure::Any = nothing\n    monster::AbstractMonster = Dracula(0)\n    percent::Percent = Percent(0.0)\n    birthdate::Date = Date(0) &(json=(dateformat=\"yyyy/mm/dd\",),)\n    percentages::Dict{Percent, Int} = Dict{Percent, Int}()\n    json_properties::JSONText = JSONText(\"\")\n    matrix::Matrix{Float64} = Matrix{Float64}(undef, 0, 0)\nend\n\njson = \"\"\"\n{\n    \"id\": 1,\n    \"address\": \"123 Main St\",\n    \"rate\": null,\n    \"franken_type\": \"b\",\n    \"notsure\": {\"key\": \"value\"},\n    \"monster\": {\n        \"monster_type\": \"vampire\",\n        \"num_victims\": 10\n    },\n    \"percent\": 0.1,\n    \"birthdate\": \"2023/10/01\",\n    \"percentages\": {\n        \"0.1\": 1,\n        \"0.2\": 2\n    },\n    \"json_properties\": {\"key\": \"value\"},\n    \"matrix\": [[1.0, 2.0], [3.0, 4.0]],\n    \"extra_key\": \"extra_value\"\n}\n\"\"\"\nJSON.parse(json, FrankenStruct)\n# FrankenStruct(1, \"Jim\", \"123 Main St\", missing, :b, JSON.Object{String, Any}(\"key\" => \"value\"), Dracula(10), Percent(0.1), Date(\"2023-10-01\"), Dict{Percent, Int64}(Percent(0.2) => 2, Percent(0.1) => 1), JSONText(\"{\"key\": \"value\"}\"), [1.0 3.0; 2.0 4.0])\n\nLet's walk through some notable features of the example above:\n\nThe name field isn't present in the JSON input, so the default value of \"Jim\" is used.\nThe address field uses a default @choosetype to determine that the JSON value is not null, so a String should be parsed for the field value.\nThe rate field has a null JSON value, so the default @choosetype recognizes it should be \"lifted\" to Missing, which then uses a predefined lift definition for Missing.\nThe type field is a Symbol, and has a fieldtag json=(name=\"franken_type\",) which means the JSON key franken_type will be used to set the field value instead of the default type field name. A default lift definition for Symbol is used to convert the JSON string value to a Symbol.\nThe notsure field is of type Any, so the default object type JSON.Object{String, Any} is used to materialize the JSON value.\nThe monster field is a polymorphic type, and the JSON value has a monster_type key that determines which concrete type to use. The @choosetype macro is used to define the logic for choosing the concrete type based on the JSON input. Note that teh x in @choosetype is a LazyValue, so we materialize via x.monster_type[] in order to compare with the string \"vampire\".\nThe percent field is a custom type Percent and the JSON.lift defines how to construct a Percent from the JSON value, which is a Float64 in this case.\nThe birthdate field uses a custom date format for parsing, specified in the JSON input.\nThe percentages field is a dictionary with keys of type Percent, which is a custom type. The liftkey function is defined to convert the JSON string keys to Percent types (parses the Float64 manually)\nThe json_properties field has a type of JSONText, which means the raw JSON will be preserved as a String of the JSONText type.\nThe matrix field is a Matrix{Float64}, so the JSON input array-of-arrays are materialized as such.\nThe extra_key field is not defined in the FrankenStruct type, so it is ignored and skipped over.\n\nNOTE: Why use JSON.Object{String, Any} as the default object type? It provides several benefits:\n\nBehaves as a drop-in replacement for Dict{String, Any}, so no loss of functionality\nPerformance! It's internal representation means memory savings and faster construction for small objects typical in JSON (vs Dict)\nInsertion order is preserved, so the order of keys in the JSON input is preserved in JSON.Object\nConvenient getproperty (i.e. obj.key) syntax is supported, even for Object{String,Any} key types (again ideal/specialized for JSON usage)\n\nJSON.Object internal representation uses a linked list, thus key lookups are linear time (O(n)). For large JSON objects, (hundreds or thousands of keys), consider using a Dict{String, Any} instead, like JSON.parse(json; dicttype=Dict{String, Any}).\n\n\n\n\n\n","category":"function"},{"location":"reference/#JSON.parsefile!","page":"API Reference","title":"JSON.parsefile!","text":"JSON.parse(json)\nJSON.parse(json, T)\nJSON.parse!(json, x)\nJSON.parsefile(filename)\nJSON.parsefile(filename, T)\nJSON.parsefile!(filename, x)\n\nParse a JSON input (string, vector, stream, LazyValue, etc.) into a Julia value. The parsefile variants take a filename, open the file, and pass the IOStream to parse.\n\nCurrently supported keyword arguments include:\n\nallownan: allows parsing NaN, Inf, and -Inf since they are otherwise invalid JSON\nninf: string to use for -Inf (default: \"-Infinity\")\ninf: string to use for Inf (default: \"Infinity\")\nnan: string to use for NaN (default: \"NaN\")\njsonlines: treat the json input as an implicit JSON array, delimited by newlines, each element being parsed from each row/line in the input\ndicttype: a custom AbstractDict type to use instead of JSON.Object{String, Any} as the default type for JSON object materialization\nnull: a custom value to use for JSON null values (default: nothing)\nstyle: a custom StructUtils.StructStyle subtype instance to be used in calls to StructUtils.make and StructUtils.lift. This allows overriding default behaviors for non-owned types.\n\nThe methods without a type specified (JSON.parse(json), JSON.parsefile(filename)), do a generic materialization into predefined default types, including:\n\nJSON object => JSON.Object{String, Any} (see note below)\nJSON array => Vector{Any}\nJSON string => String\nJSON number => Int64, BigInt, Float64, or BigFloat\nJSON true => true\nJSON false => false\nJSON null => nothing\n\nWhen a type T is specified (JSON.parse(json, T), JSON.parsefile(filename, T)), materialization to a value of type T will be attempted utilizing machinery and interfaces provided by the StructUtils.jl package, including:\n\nFor JSON objects, JSON keys will be matched against field names of T with a value being constructed via T(args...)\nIf T was defined with the @noarg macro, an empty instance will be constructed, and field values set as JSON keys match field names\nIf T had default field values defined using the @defaults or @kwarg macros (from StructUtils.jl package), those will be set in the value of T unless different values are parsed from the JSON\nIf T was defined with the @nonstruct macro, the struct will be treated as a primitive type and constructed using the lift function rather than from field values\nJSON keys that don't match field names in T will be ignored (skipped over)\nIf a field in T has a name fieldtag, the name value will be used to match JSON keys instead\nIf T or any recursive field type of T is abstract, an appropriate JSON.@choosetype T x -> ... definition should exist for \"choosing\" a concrete type at runtime; default type choosing exists for Union{T, Missing} and Union{T, Nothing} where the JSON value is checked if null. If the Any type is encountered, the default materialization types will be used (JSON.Object, Vector{Any}, etc.)\nFor any non-JSON-standard non-aggregate (i.e. non-object, non-array) field type of T, a JSON.lift(::Type{T}, x) = ... definition can be defined for how to \"lift\" the default JSON value (String, Number, Bool, nothing) to the type T; a default lift definition exists, for example, for JSON.lift(::Type{Missing}, x) = missing where the standard JSON value for null is nothing and it can be \"lifted\" to missing\nFor any T or recursive field type of T that is AbstractDict, non-string/symbol/integer keys will need to have a StructUtils.liftkey(::Type{T}, x)) definition for how to \"lift\" the JSON string key to the key type of T\n\nFor any T or recursive field type of T that is JSON.JSONText, the next full raw JSON value will be preserved in the JSONText wrapper as-is.\n\nFor the unique case of nested JSON arrays and prior knowledge of the expected dimensionality, a target type T can be given as an AbstractArray{T, N} subtype. In this case, the JSON array data is materialized as an n-dimensional array, where: the number of JSON array nestings must match the Julia array dimensionality (N), nested JSON arrays at matching depths are assumed to have equal lengths, and the length of the innermost JSON array is the 1st dimension length and so on. For example, the JSON array [[[1.0,2.0]]] would be materialized as a 3-dimensional array of Float64 with sizes (2, 1, 1), when called like JSON.parse(\"[[[1.0,2.0]]]\", Array{Float64, 3}). Note that n-dimensional Julia arrays are written to json as nested JSON arrays by default, to enable lossless re-parsing, though the dimensionality must still be provided explicitly to the call to parse (i.e. default parsing via JSON.parse(json) will result in plain nested Vector{Any}s returned).\n\nExamples:\n\nusing Dates\n\nabstract type AbstractMonster end\n\nstruct Dracula <: AbstractMonster\n    num_victims::Int\nend\n\nstruct Werewolf <: AbstractMonster\n    witching_hour::DateTime\nend\n\nJSON.@choosetype AbstractMonster x -> x.monster_type[] == \"vampire\" ? Dracula : Werewolf\n\nstruct Percent <: Number\n    value::Float64\nend\n\nJSON.lift(::Type{Percent}, x) = Percent(Float64(x))\nStructUtils.liftkey(::Type{Percent}, x::String) = Percent(parse(Float64, x))\n\n@defaults struct FrankenStruct\n    id::Int = 0\n    name::String = \"Jim\"\n    address::Union{Nothing, String} = nothing\n    rate::Union{Missing, Float64} = missing\n    type::Symbol = :a &(json=(name=\"franken_type\",),)\n    notsure::Any = nothing\n    monster::AbstractMonster = Dracula(0)\n    percent::Percent = Percent(0.0)\n    birthdate::Date = Date(0) &(json=(dateformat=\"yyyy/mm/dd\",),)\n    percentages::Dict{Percent, Int} = Dict{Percent, Int}()\n    json_properties::JSONText = JSONText(\"\")\n    matrix::Matrix{Float64} = Matrix{Float64}(undef, 0, 0)\nend\n\njson = \"\"\"\n{\n    \"id\": 1,\n    \"address\": \"123 Main St\",\n    \"rate\": null,\n    \"franken_type\": \"b\",\n    \"notsure\": {\"key\": \"value\"},\n    \"monster\": {\n        \"monster_type\": \"vampire\",\n        \"num_victims\": 10\n    },\n    \"percent\": 0.1,\n    \"birthdate\": \"2023/10/01\",\n    \"percentages\": {\n        \"0.1\": 1,\n        \"0.2\": 2\n    },\n    \"json_properties\": {\"key\": \"value\"},\n    \"matrix\": [[1.0, 2.0], [3.0, 4.0]],\n    \"extra_key\": \"extra_value\"\n}\n\"\"\"\nJSON.parse(json, FrankenStruct)\n# FrankenStruct(1, \"Jim\", \"123 Main St\", missing, :b, JSON.Object{String, Any}(\"key\" => \"value\"), Dracula(10), Percent(0.1), Date(\"2023-10-01\"), Dict{Percent, Int64}(Percent(0.2) => 2, Percent(0.1) => 1), JSONText(\"{\"key\": \"value\"}\"), [1.0 3.0; 2.0 4.0])\n\nLet's walk through some notable features of the example above:\n\nThe name field isn't present in the JSON input, so the default value of \"Jim\" is used.\nThe address field uses a default @choosetype to determine that the JSON value is not null, so a String should be parsed for the field value.\nThe rate field has a null JSON value, so the default @choosetype recognizes it should be \"lifted\" to Missing, which then uses a predefined lift definition for Missing.\nThe type field is a Symbol, and has a fieldtag json=(name=\"franken_type\",) which means the JSON key franken_type will be used to set the field value instead of the default type field name. A default lift definition for Symbol is used to convert the JSON string value to a Symbol.\nThe notsure field is of type Any, so the default object type JSON.Object{String, Any} is used to materialize the JSON value.\nThe monster field is a polymorphic type, and the JSON value has a monster_type key that determines which concrete type to use. The @choosetype macro is used to define the logic for choosing the concrete type based on the JSON input. Note that teh x in @choosetype is a LazyValue, so we materialize via x.monster_type[] in order to compare with the string \"vampire\".\nThe percent field is a custom type Percent and the JSON.lift defines how to construct a Percent from the JSON value, which is a Float64 in this case.\nThe birthdate field uses a custom date format for parsing, specified in the JSON input.\nThe percentages field is a dictionary with keys of type Percent, which is a custom type. The liftkey function is defined to convert the JSON string keys to Percent types (parses the Float64 manually)\nThe json_properties field has a type of JSONText, which means the raw JSON will be preserved as a String of the JSONText type.\nThe matrix field is a Matrix{Float64}, so the JSON input array-of-arrays are materialized as such.\nThe extra_key field is not defined in the FrankenStruct type, so it is ignored and skipped over.\n\nNOTE: Why use JSON.Object{String, Any} as the default object type? It provides several benefits:\n\nBehaves as a drop-in replacement for Dict{String, Any}, so no loss of functionality\nPerformance! It's internal representation means memory savings and faster construction for small objects typical in JSON (vs Dict)\nInsertion order is preserved, so the order of keys in the JSON input is preserved in JSON.Object\nConvenient getproperty (i.e. obj.key) syntax is supported, even for Object{String,Any} key types (again ideal/specialized for JSON usage)\n\nJSON.Object internal representation uses a linked list, thus key lookups are linear time (O(n)). For large JSON objects, (hundreds or thousands of keys), consider using a Dict{String, Any} instead, like JSON.parse(json; dicttype=Dict{String, Any}).\n\n\n\n\n\n","category":"function"},{"location":"reference/#JSON.print","page":"API Reference","title":"JSON.print","text":"JSON.json(x) -> String\nJSON.json(io, x)\nJSON.json(file_name, x)\n\nSerialize x to JSON format. The 1st method takes just the object and returns a String. In the 2nd method, io is an IO object, and the JSON output will be written to it. For the 3rd method, file_name is a String, a file will be opened and the JSON output will be written to it.\n\nAll methods accept the following keyword arguments:\n\nomit_null::Union{Bool, Nothing}=nothing: Controls whether struct fields that are undefined or are nothing are included in the JSON output. If true, only non-null fields are written. If false, all fields are included regardless of being undefined or nothing. If nothing, the behavior is determined by JSON.omit_null(::Type{T}), which is false by default.\nomit_empty::Union{Bool, Nothing}=nothing: Controls whether struct fields that are empty are included in the JSON output. If true, empty fields are excluded. If false, empty fields are included. If nothing, the behavior is determined by JSON.omit_empty(::Type{T}).\nallownan::Bool=false: If true, allow Inf, -Inf, and NaN in the output. If false, throw an error if Inf, -Inf, or NaN is encountered.\njsonlines::Bool=false: If true, input must be array-like and the output will be written in the JSON Lines format, where each element of the array is written on a separate line (i.e. separated by a single newline character `\n\n).   Iffalse`, the output will be written in the standard JSON format.\n\npretty::Union{Integer,Bool}=false: Controls pretty printing of the JSON output. If true, the output will be pretty-printed with 2 spaces of indentation. If an integer, it will be used as the number of spaces of indentation. If false or 0, the output will be compact. Note: Pretty printing is not supported when jsonlines=true.\ninline_limit::Int=0: For arrays shorter than this limit, pretty printing will be disabled (indentation set to 0).\nninf::String=\"-Infinity\": Custom string representation for negative infinity.\ninf::String=\"Infinity\": Custom string representation for positive infinity.\nnan::String=\"NaN\": Custom string representation for NaN.\nfloat_style::Symbol=:shortest: Controls how floating-point numbers are formatted. Options are:\n:shortest: Use the shortest representation that preserves the value\n:fixed: Use fixed-point notation\n:exp: Use exponential notation\nfloat_precision::Int=1: Number of decimal places to use when float_style is :fixed or :exp.\nbufsize::Int=2^22: Buffer size in bytes for IO operations. When writing to IO, the buffer will be flushed  to the IO stream once it reaches this size. This helps control memory usage during large write operations. Default is 4MB (2^22 bytes). This parameter is ignored when returning a String.\nstyle::JSONStyle=JSONWriteStyle(): Custom style object that controls serialization behavior. This allows customizing   certain aspects of serialization, like defining a custom lower method for a non-owned type. Like struct MyStyle <: JSONStyle end,   JSON.lower(x::Rational) = (num=x.num, den=x.den), then calling JSON.json(1//3; style=MyStyle()) will output   {\"num\": 1, \"den\": 3}.\n\nBy default, x must be a JSON-serializable object. Supported types include:\n\nAbstractString => JSON string: types must support the AbstractString interface, specifically with support for ncodeunits and codeunit(x, i).\nBool => JSON boolean: must be true or false\nNothing => JSON null: must be the nothing singleton value\nNumber => JSON number: Integer subtypes or Union{Float16, Float32, Float64} have default implementations for other Number types, JSON.tostring is first called to convert the value to a String before being written directly to JSON output\nAbstractArray/Tuple/AbstractSet => JSON array: objects for which JSON.arraylike returns true  are output as JSON arrays. arraylike is defined by default for AbstractArray, AbstractSet, Tuple, and Base.Generator. For other types that define, they must also properly implement StructUtils.applyeach to iterate over the index => elements pairs. Note that arrays with dimensionality > 1 are written as nested arrays, with N nestings for N dimensions, and the 1st dimension is always the innermost nested JSON array (column-major order).\nAbstractDict/NamedTuple/structs => JSON object: if a value doesn't fall into any of the above categories, it is output as a JSON object. StructUtils.applyeach is called, which has appropriate implementations for AbstractDict, NamedTuple, and structs, where field names => values are iterated over. Field names can be output with an alternative name via field tag overload, like field::Type &(json=(name=\"alternative_name\",),)\n\nIf an object is not JSON-serializable, an override for JSON.lower can be defined to convert it to a JSON-serializable object. Some default lower defintions are defined in JSON itself, for example:\n\nStructUtils.lower(::Missing) = nothing\nStructUtils.lower(x::Symbol) = String(x)\nStructUtils.lower(x::Union{Enum, AbstractChar, VersionNumber, Cstring, Cwstring, UUID, Dates.TimeType}) = string(x)\nStructUtils.lower(x::Regex) = x.pattern\n\nThese allow common Base/stdlib types to be serialized in an expected format.\n\nCircular references are tracked automatically and cycles are broken by writing null for any children references.\n\nFor pre-formatted JSON data as a String, use JSONText(json) to write the string out as-is.\n\nFor AbstractDict objects with non-string keys, StructUtils.lowerkey will be called before serializing. This allows aggregate or other types of dict keys to be converted to an appropriate string representation. See StructUtils.liftkey for the reverse operation, which is called when parsing JSON data back into a dict type.\n\nNOTE: JSON.json should not be overloaded directly by custom types as this isn't robust for various output options (IO, String, etc.) nor recursive situations. Types should define an appropriate JSON.lower definition instead.\n\nNOTE: JSON.json(str, indent::Integer) is special-cased for backwards compatibility with pre-1.0 JSON.jl, as this typically would mean \"write out the indent integer to file str\". As writing out a single integer to a file is extremely rare, it was decided to keep the pre-1.0 behavior for compatibility reasons.\n\nExamples:\n\nusing Dates\n\nabstract type AbstractMonster end\n\nstruct Dracula <: AbstractMonster\n    num_victims::Int\nend\n\nstruct Werewolf <: AbstractMonster\n    witching_hour::DateTime\nend\n\nstruct Percent <: Number\n    value::Float64\nend\n\nJSON.lower(x::Percent) = x.value\nStructUtils.lowerkey(x::Percent) = string(x.value)\n\n@noarg mutable struct FrankenStruct\n    id::Int\n    name::String # no default to show serialization of an undefined field\n    address::Union{Nothing, String} = nothing\n    rate::Union{Missing, Float64} = missing\n    type::Symbol = :a &(json=(name=\"franken_type\",),)\n    notsure::Any = JSON.Object(\"key\" => \"value\")\n    monster::AbstractMonster = Dracula(10) &(json=(lower=x -> x isa Dracula ? (monster_type=\"vampire\", num_victims=x.num_victims) : (monster_type=\"werewolf\", witching_hour=x.witching_hour),),)\n    percent::Percent = Percent(0.5)\n    birthdate::Date = Date(2025, 1, 1) &(json=(dateformat=\"yyyy/mm/dd\",),)\n    percentages::Dict{Percent, Int} = Dict{Percent, Int}(Percent(0.0) => 0, Percent(1.0) => 1)\n    json_properties::JSONText = JSONText(\"{\"key\": \"value\"}\")\n    matrix::Matrix{Float64} = [1.0 2.0; 3.0 4.0]\n    extra_field::Any = nothing &(json=(ignore=true,),)\nend\n\nfranken = FrankenStruct()\nfranken.id = 1\n\njson = JSON.json(franken; omit_null=false)\n# \"{\"id\":1,\"name\":null,\"address\":null,\"rate\":null,\"franken_type\":\"a\",\"notsure\":{\"key\":\"value\"},\"monster\":{\"monster_type\":\"vampire\",\"num_victims\":10},\"percent\":0.5,\"birthdate\":\"2025/01/01\",\"percentages\":{\"1.0\":1,\"0.0\":0},\"json_properties\":{\"key\": \"value\"},\"matrix\":[[1.0,3.0],[2.0,4.0]]}\"\n\nA few comments on the JSON produced in the example above:\n\nThe name field was #undef, and thus was serialized as null.\nThe address and rate fields were nothing and missing, respectively, and thus were serialized as null.\nThe type field has a name field tag, so the JSON key for this field is franken_type instead of type.\nThe notsure field is a JSON.Object, so it is serialized as a JSON object.\nThe monster field is a AbstractMonster, which is a custom type. It has a lower field tag that specifies how the value of this field specifically (not all AbstractMonster) should be serialized\nThe percent field is a Percent, which is a custom type. It has a lower method that specifies how Percent values should be serialized\nThe birthdate field has a dateformat field tag, so the value follows the format (yyyy/mm/dd) instead of the default date ISO format (yyyy-mm-dd)\nThe percentages field is a Dict{Percent, Int}, which is a custom type. It has a lowerkey method that specifies how Percent keys should be serialized as strings\nThe json_properties field is a JSONText, so the JSONText value is serialized as-is\nThe matrix field is a Matrix{Float64}, which is a custom type. It is serialized as a JSON array, with the first dimension being the innermost nested JSON array (column-major order)\nThe extra_field field has a ignore field tag, so it is skipped when serializing\n\n\n\n\n\n","category":"function"},{"location":"reference/#JSON.tostring-Tuple{Any}","page":"API Reference","title":"JSON.tostring","text":"JSON.tostring(x)\n\nOverloadable function that allows non-Integer Number types to convert themselves to a String that is then used when serializing x to JSON. Note that if the result of tostring is not a valid JSON number, it will be serialized as a JSON string, with double quotes around it.\n\nAn example overload would look something like:\n\nJSON.tostring(x::MyDecimal) = string(x)\n\n\n\n\n\n","category":"method"},{"location":"reference/#JSON.@omit_empty-Tuple{Any}","page":"API Reference","title":"JSON.@omit_empty","text":"@omit_empty struct T ...\n@omit_empty T\n\nConvenience macro to set omit_empty(::Type{T}) to true for the struct T. Can be used in three ways:\n\nIn front of a struct definition: @omit_empty struct T ... end\nApplied to an existing struct name: @omit_empty T\nChained with other macros: @omit_empty @other_macro struct T ... end\n\n\n\n\n\n","category":"macro"},{"location":"reference/#JSON.@omit_null-Tuple{Any}","page":"API Reference","title":"JSON.@omit_null","text":"@omit_null struct T ...\n@omit_null T\n\nConvenience macro to set omit_null(::Type{T}) to true for the struct T. Can be used in three ways:\n\nIn front of a struct definition: @omit_null struct T ... end\nApplied to an existing struct name: @omit_null T\nChained with other macros: @omit_null @defaults struct T ... end\n\nThe macro automatically handles complex macro expansions by walking the expression tree to find struct definitions, making it compatible with macros like StructUtils.@defaults.\n\nExamples\n\n# Method 1: Struct annotation\n@omit_null struct Person\n    name::String\n    email::Union{Nothing, String}\nend\n\n# Method 2: Apply to existing struct\nstruct User\n    id::Int\n    profile::Union{Nothing, String}\nend\n@omit_null User\n\n# Method 3: Chain with @defaults\n@omit_null @defaults struct Employee\n    name::String = \"Anonymous\"\n    manager::Union{Nothing, String} = nothing\nend\n\n\n\n\n\n","category":"macro"},{"location":"#JSON.jl","page":"JSON.jl","title":"JSON.jl","text":"","category":"section"},{"location":"","page":"JSON.jl","title":"JSON.jl","text":"JSON Julia package repo.","category":"page"},{"location":"","page":"JSON.jl","title":"JSON.jl","text":"","category":"page"},{"location":"reading/#JSON-Reading","page":"JSON Reading","title":"JSON Reading","text":"","category":"section"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"This guide to reading JSON in the JSON.jl package aims to:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Provide a comprehensive overview of the JSON reading process.\nExplain the various options and configurations available for reading JSON data.\nOffer practical examples to illustrate the usage of different functions and options.","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"","category":"page"},{"location":"reading/#Core-JSON-Parsing-JSON.lazy-and-JSON.LazyValue","page":"JSON Reading","title":"Core JSON Parsing - JSON.lazy and JSON.LazyValue","text":"","category":"section"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"There are several \"entrypoints\" to reading JSON in JSON.jl, including:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"JSON.parse/JSON.parse!\nJSON.parsefile/JSON.parsefile!\nJSON.lazy/JSON.lazyfile\nJSON.isvalidjson","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"These functions are all built to accept the same kinds of JSON inputs:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Accepted json sources Notes\nAbstractString UTFâ€‘8; UTFâ€‘8â€‘BOM handled automatically\nAbstractVector{UInt8} zeroâ€‘copy if already bytes\nIO, IOStream, Base.AbstractCmd stream fully read into a byte vector","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"The core JSON parsing machinery is hence built around having an AbstractVector{UInt8} or AbstractString JSON input where individual bytes can be parsed to identify JSON structure, validate syntax, and ultimately produce Julia-level values.","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Each entrypoint function first calls JSON.lazy, which will consume the JSON input until the type of the next JSON value can be identified ({ for objects, [ for arrays, \" for strings, t for true, f for false, n for null, and - or a digit for numbers). JSON.lazy returns a JSON.LazyValue, which wraps the JSON input buffer (AbstractVector{UInt8} or AbstractString), and marks the byte position the value starts at, the type of the value, and any keyword arguments that were provided that may affect parsing. Currently supported parsing-specific keyword arguments to JSON.lazy (and thus all other entrypoint functions) include:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"allownan::Bool = false: whether \"special\" float values shoudl be allowed while parsing (NaN, Inf, -Inf); these values are specifically not allowed in the JSON spec, but many JSON libraries allow reading/writing\nninf::String = \"-Infinity\": the string that will be used to parse -Inf if allownan=true\ninf::String = \"Infinity\": the string that will be used to parse Inf if allownan=true\nnan::String = \"NaN\": the string that will be sued to parse NaN if allownan=true\njsonlines::Bool = false: whether the JSON input should be treated as an implicit array, with newlines separating individual JSON elements with no leading '[' or trailing ']' characters. Common in logging or streaming workflows. Defaults to true when used with JSON.parsefile and the filename extension is .jsonl or ndjson. Note this ensures that parsing will always return an array at the root-level.\nMaterialization-specific keyword arguments (i.e. they affect materialization, but not parsing)\ndicttype = JSON.Object{String, Any}: type to parse JSON objects as by default (recursively)\nnull = nothing: value to return for JSON null value","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"So what can we do with a JSON.LazyValue?","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"julia> x = JSON.lazy(\"{\\\"a\\\": 1, \\\"b\\\": null, \\\"c\\\": true, \\\"d\\\": false, \\\"e\\\": \\\"\\\", \\\"f\\\": [1,2,3], \\\"g\\\": {\\\"h\\\":{\\\"i\\\":\\\"foo\\\"}}}\")\nLazyObject{String} with 7 entries:\n  \"a\" => JSON.LazyValue(1)\n  \"b\" => JSON.LazyValue(nothing)\n  \"c\" => JSON.LazyValue(true)\n  \"d\" => JSON.LazyValue(false)\n  \"e\" => JSON.LazyValue(\"\")\n  \"f\" => LazyValue[JSON.LazyValue(1), JSON.LazyValue(2), JSON.LazyValue(3)]\n  \"g\" => LazyObject{String}(\"h\"=>LazyObject{String}(\"i\"=>JSON.LazyValue(\"foo\")))","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Note that for convenience at the REPL, special show overloads enable displaying the full contents of lazy values. In reality, remember the LazyValue only marks the position of a value within the JSON. LazyValues support convenient syntax for both navigating their structure and materializing, with an aim to support lazy workflows. Examples include:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"# convenient \"get\" syntax on lazy objects\njulia> x.a\nJSON.LazyValue(1)\n\njulia> x[:b]\nJSON.LazyValue(nothing)\n\njulia> x[\"c\"]\nJSON.LazyValue(true)\n\njulia> propertynames(x)\n7-element Vector{Symbol}:\n :a\n :b\n :c\n :d\n :e\n :f\n :g\n\njulia> x.g.h.i\nJSON.LazyValue(\"foo\")\n\n# array indexing on lazy arrays\njulia> x.f[1]\nJSON.LazyValue(1)\n\njulia> x.f[end]\nJSON.LazyValue(3)\n\njulia> x.f[1:3]\n3-element StructUtils.Selectors.List{Any}:\n JSON.LazyValue(1)\n JSON.LazyValue(2)\n JSON.LazyValue(3)\n\n# default materialization of any LazyValue via empty getindex\njulia> x.a[]\n1\n\njulia> x[]\nJSON.Object{String, Any} with 7 entries:\n  \"a\" => 1\n  \"b\" => nothing\n  \"c\" => true\n  \"d\" => false\n  \"e\" => \"\"\n  \"f\" => Any[1, 2, 3]\n  \"g\" => Object{String, Any}(\"h\"=>Object{String, Any}(\"i\"=>\"foo\"))","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Let's take a closer look at one of these examples and talk through what's going on under the hood. For x.g.h.i, this deeply nested access of the \"foo\" value, is a chain of getproperty calls, with each call (i.e. y = x.g, then z = y.h, etc.) returning a LazyValue of where the next nested object begins in the raw JSON. With the final getproperty call (h.i), a non-object LazyValue(\"foo\") is returned. In our raw JSON, the \"foo\" value is located near the end, so we can infer that by doing x.g.h.i, the underlying JSON was parsed or navigated until the i key was found and its value returned. In this example, \"foo\" is indeed the last value in our raw JSON, but in the example of x.c, we can also be assured that only as much JSON as necessary was parsed/navigated before returning LazyValue(true). In this way, the various syntax calls (getproperty, getindex, etc.) on LazyValues can be thought of as purely navigational as opposed to anything related to materialization. Indeed, the very purpose of the lazy machinery in JSON.jl is to allow lazily navigating, specifically without needing to materialize anything along the way.","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Ok, but at some point, we do actually need Julia values to operate on, so let's shift to how materialization works in JSON.jl.","category":"page"},{"location":"reading/#JSON.parse-Untyped-materialization","page":"JSON Reading","title":"JSON.parse - Untyped materialization","text":"","category":"section"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"In the LazyValue syntax example, it was shown that empty getindex will result in a \"default\" materialization of a LazyValue:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"julia> x[]\nJSON.Object{String, Any} with 7 entries:\n  \"a\" => 1\n  \"b\" => nothing\n  \"c\" => true\n  \"d\" => false\n  \"e\" => \"\"\n  \"f\" => Any[1, 2, 3]\n  \"g\" => Object{String, Any}(\"h\"=>Object{String, Any}(\"i\"=>\"foo\"))","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Under the hood, this getindex call is really calling JSON.parse(lazyvalue). JSON.parse can also be called as a main entrypoint function with all the same input types as JSON.lazy. This form of parse is referred to as \"untyped parsing\" or \"untyped materialization\". It allocates and materializes the raw JSON values into appropriate \"default\" Julia-level values. In particular:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"JSON construct Default Julia value\nobject JSON.Object{String,Any} (orderâ€‘preserving drop-in replacement for Dict)\narray Vector{Any}\nstring String\nnumber Int64, BigInt, Float64, or BigFloat\nnull nothing\ntrue/false Bool","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Mostly vanilla, but what is JSON.Object? It is a custom AbstractDict using an internal linked-list implementation that preserves insertion order, behaves as a drop-in replacement for Dict, and allows memory and performance benefits vs. Dict for small # of entries. It also supports natural JSON-object-like syntax for accessing or setting values, like x.g.h.i and x.c = false.","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Because Object uses a linked-list implementation, key lookups are O(n), performing a linear scan on each access. For small number of entries (dozens), the real-performance difference vs. Dict hash-lookup is negligible, but for large objects, this can be prohibitive. For these cases, it's recommended to materialize JSON objects as regular Julia Dict, by utilizing the dicttype keyword argument, like: JSON.parse(json; dicttype=Dict{String, Any}).","category":"page"},{"location":"reading/#JSON.parse-Typed-materialization","page":"JSON Reading","title":"JSON.parse - Typed materialization","text":"","category":"section"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"While untyped materialization is convenient for quick exploration, one of the most powerful features of JSON.jl is its ability to directly parse JSON into concrete Julia types. This is done by providing a type as the second argument to JSON.parse and opens up a world of type-safe JSON parsing with minimal boilerplate.","category":"page"},{"location":"reading/#Basic-usage-with-structs","page":"JSON Reading","title":"Basic usage with structs","text":"","category":"section"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Let's start with a simple example. Suppose we have a Julia struct and a JSON string we want to parse into that type:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"struct Person\n    name::String\n    age::Int\nend\n\njson = \"\"\"{\"name\": \"Alice\", \"age\": 30}\"\"\"\nperson = JSON.parse(json, Person)\n# Person(\"Alice\", 30)","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"With this approach, JSON.jl automatically:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Matches JSON object keys to struct field names\nConverts values to the appropriate field types\nConstructs the struct with the parsed values","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"This works for nested structs too:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"struct Address\n    street::String\n    city::String\n    country::String\nend\n\nstruct Employee\n    name::String\n    age::Int\n    address::Address\nend\n\njson = \"\"\"\n{\n    \"name\": \"Bob\",\n    \"age\": 42,\n    \"address\": {\n        \"street\": \"123 Main St\",\n        \"city\": \"Anytown\",\n        \"country\": \"USA\"\n    }\n}\n\"\"\"\n\nemployee = JSON.parse(json, Employee)","category":"page"},{"location":"reading/#Arrays-and-collections","page":"JSON Reading","title":"Arrays and collections","text":"","category":"section"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"You can parse JSON arrays directly into Julia arrays with a specific element type:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"# Parse into a Vector of integers\nints = JSON.parse(\"[1, 2, 3, 4, 5]\", Vector{Int})\n# 5-element Vector{Int64}: [1, 2, 3, 4, 5]\n\n# Parse into a Vector of custom structs\npeople = JSON.parse(\"\"\"\n[\n    {\"name\": \"Alice\", \"age\": 30},\n    {\"name\": \"Bob\", \"age\": 42}\n]\n\"\"\", Vector{Person})\n# 2-element Vector{Person}: [Person(\"Alice\", 30), Person(\"Bob\", 42)]","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"A particularly powerful feature is the ability to parse nested arrays into multi-dimensional arrays:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"# Parse a nested array into a Matrix\nmatrix = JSON.parse(\"[[1, 2], [3, 4]]\", Matrix{Int})\n# 2Ã—2 Matrix{Int64}:\n#  1  3\n#  2  4","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Note that for matrices, JSON.jl expects column-major order (Julia's native format). The innermost arrays become the columns of the matrix.","category":"page"},{"location":"reading/#Primitive-and-simple-types","page":"JSON Reading","title":"Primitive and simple types","text":"","category":"section"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"JSON.jl can also parse JSON values directly into primitive types:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"# Parse a JSON number into an Int\nn = JSON.parse(\"42\", Int)\n# 42\n\n# Parse a JSON string into a String\ns = JSON.parse(\"\\\"hello\\\"\", String)\n# \"hello\"\n\n# Parse a JSON string into a custom type like UUID\nuuid = JSON.parse(\"\\\"123e4567-e89b-12d3-a456-426614174000\\\"\", UUID)\n# UUID(\"123e4567-e89b-12d3-a456-426614174000\")\n\n# Parse a JSON string into a Date\ndate = JSON.parse(\"\\\"2023-05-08\\\"\", Date)\n# Date(\"2023-05-08\")","category":"page"},{"location":"reading/#Type-conversions-and-handling-nulls","page":"JSON Reading","title":"Type conversions and handling nulls","text":"","category":"section"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"JSON.jl provides smart handling for Union types, especially for dealing with potentially null values:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"struct OptionalData\n    id::Int\n    description::Union{String, Nothing}\n    score::Union{Float64, Missing}\nend\n\njson = \"\"\"\n{\n    \"id\": 123,\n    \"description\": null,\n    \"score\": null\n}\n\"\"\"\n\ndata = JSON.parse(json, OptionalData)\n# OptionalData(123, nothing, missing)","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Note how JSON.jl automatically:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Converts JSON null to Julia nothing for Union{T, Nothing} fields\nConverts JSON null to Julia missing for Union{T, Missing} fields","category":"page"},{"location":"reading/#Field-customization-through-tags","page":"JSON Reading","title":"Field customization through tags","text":"","category":"section"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"You can customize how JSON fields map to struct fields using \"field tags\" from StructUtils.jl via the struct macros (@tags, @defaults, @kwarg, or @noarg):","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"using JSON, StructUtils\n\n@tags struct UserProfile\n    user_id::Int &(json=(name=\"id\",),)\n    first_name::String &(json=(name=\"firstName\",),)\n    last_name::String &(json=(name=\"lastName\",),)\n    birth_date::Date &(json=(dateformat=dateformat\"yyyy/mm/dd\",),)\nend\n\njson = \"\"\"\n{\n    \"id\": 42,\n    \"firstName\": \"Jane\",\n    \"lastName\": \"Doe\",\n    \"birth_date\": \"1990/01/15\"\n}\n\"\"\"\n\nuser = JSON.parse(json, UserProfile)\n# UserProfile(42, \"Jane\", \"Doe\", Date(\"1990-01-15\"))","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"The &(json=(name=\"...\",),) syntax lets you:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Map differently named JSON keys to your struct fields\nSpecify custom date formats for parsing dates\nAnd many other customizations","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Field tags are really named tuples of values, prefixed with the & character, so note the trailing , when the named tuple has a single element. Also note that in this example, we \"namespaced\" our field tags with the json=(...) key. Then when \"making\" our struct, only the json=(...) field tags are considered. This is because JSON.jl defines json as a \"field tag key\" for its custom JSONStyle, then passes a JSONStyle to be used when parsing. That means you could specify the field tag like &(name=\"id,), but if the field then is also used by any other package, it would also see that name. Sometimes that may be desirable, but there are also cases where you want the namespacing, like: &(json=(name=\"id\",), postgres=(name=\"user_id\",)).","category":"page"},{"location":"reading/#Default-values-with-@defaults","page":"JSON Reading","title":"Default values with @defaults","text":"","category":"section"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"When some JSON fields might be missing, you can provide default values similar to field tags using any of the struct macros (@tags, @defaults, @kwarg, or @noarg):","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"@defaults struct Configuration\n    port::Int = 8080\n    host::String = \"localhost\"\n    debug::Bool = false\n    timeout::Int = 30\nend\n\n# Even with missing fields, parsing succeeds with defaults\njson = \"\"\"{\"port\": 9000}\"\"\"\nconfig = JSON.parse(json, Configuration)\n# Configuration(9000, \"localhost\", false, 30)","category":"page"},{"location":"reading/#Non-struct-like-types-with-@nonstruct","page":"JSON Reading","title":"Non-struct-like types with @nonstruct","text":"","category":"section"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"What if you have a custom struct that you want to behave more like a primitive type rather than a struct? For example, you might want a custom email type that should be serialized as a JSON string rather than a JSON object.","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"The @nonstruct macro is perfect for this use case. By marking your struct as non-struct-like, you tell JSON.jl to treat it as a primitive type that should be converted directly using lift and lower methods rather than constructing it from field values.","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Here's an example of a custom email type that should be serialized as a JSON string:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"using JSON\n\n@nonstruct struct Email\n    value::String\n    \n    function Email(value::String)\n        # Validate email format\n        if !occursin(r\"^[^@]+@[^@]+\\.[^@]+$\", value)\n            throw(ArgumentError(\"Invalid email format: $value\"))\n        end\n        new(value)\n    end\nend\n\n# Define how to convert from various sources to Email\nJSON.lift(::Type{Email}, x::String) = Email(x)\n\n# Define how to convert Email to a serializable format\nJSON.lower(x::Email) = x.value\n\n# Now you can use Email in your structs and it will be serialized as a string\n@defaults struct User\n    id::Int = 1\n    name::String = \"default\"\n    email::Email\nend\n\n# Create a user with an email\nuser = User(email=Email(\"alice@example.com\"))\n\n# Convert to JSON - email will be a string, not an object\njson_string = JSON.json(user)\n# Result: {\"id\":1,\"name\":\"default\",\"email\":\"alice@example.com\"}\n\n# Parse back from JSON\nuser_again = JSON.parse(json_string, User)","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Another example - a custom numeric type that represents a percentage:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"@nonstruct struct Percent <: Number\n    value::Float64\n    \n    function Percent(value::Real)\n        if value < 0 || value > 100\n            throw(ArgumentError(\"Percentage must be between 0 and 100\"))\n        end\n        new(Float64(value))\n    end\nend\n\n# Convert from various numeric types\nJSON.lift(::Type{Percent}, x::Number) = Percent(x)\nJSON.lift(::Type{Percent}, x::String) = Percent(parse(Float64, x))\n\n# Convert to a simple number for serialization\nJSON.lower(x::Percent) = x.value\n\n# Use in a struct\n@defaults struct Product\n    name::String = \"default\"\n    discount::Percent = Percent(0.0)\nend\n\n# Create and serialize\nproduct = Product(discount=Percent(15.5))\njson_string = JSON.json(product)\n# Result: {\"name\":\"default\",\"discount\":15.5}","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"The key points about @nonstruct:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"No field defaults or tags: Since you're opting out of struct-like behavior, field defaults and tags are not supported.\nRequires lift and lower methods: You must define how to convert to/from your type.\nFields are private: The struct's fields are considered implementation details for the parsing process.\nPerfect for wrapper types: Great for types that wrap primitives but need custom validation or behavior.","category":"page"},{"location":"reading/#Advanced-Example:-The-FrankenStruct","page":"JSON Reading","title":"Advanced Example: The FrankenStruct","text":"","category":"section"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Let's explore a more comprehensive example that showcases many of JSON.jl's advanced typed parsing features:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"using Dates, JSON, StructUtils\n\n# First, define some types for polymorphic parsing\nabstract type AbstractMonster end\n\nstruct Dracula <: AbstractMonster\n    num_victims::Int\nend\n\nstruct Werewolf <: AbstractMonster\n    witching_hour::DateTime\nend\n\n# Define a custom type chooser for AbstractMonster\nJSON.@choosetype AbstractMonster x -> x.monster_type[] == \"vampire\" ? Dracula : Werewolf\n\n# Define a custom numeric type with special parsing\nstruct Percent <: Number\n    value::Float64\nend\n\n# Custom lifting for the Percent type\nJSON.lift(::Type{Percent}, x) = Percent(Float64(x))\nStructUtils.liftkey(::Type{Percent}, x::String) = Percent(parse(Float64, x))\n\n# Our complex struct with various field types and defaults\n@defaults struct FrankenStruct\n    id::Int = 0\n    name::String = \"Jim\"\n    address::Union{Nothing, String} = nothing\n    rate::Union{Missing, Float64} = missing\n    type::Symbol = :a &(json=(name=\"franken_type\",),)\n    notsure::Any = nothing\n    monster::AbstractMonster = Dracula(0)\n    percent::Percent = Percent(0.0)\n    birthdate::Date = Date(0) &(json=(dateformat=\"yyyy/mm/dd\",),)\n    percentages::Dict{Percent, Int} = Dict{Percent, Int}()\n    json_properties::JSONText = JSONText(\"\")\n    matrix::Matrix{Float64} = Matrix{Float64}(undef, 0, 0)\nend\n\n# A complex JSON input with various features to demonstrate\njson = \"\"\"\n{\n    \"id\": 1,\n    \"address\": \"123 Main St\",\n    \"rate\": null,\n    \"franken_type\": \"b\",\n    \"notsure\": {\"key\": \"value\"},\n    \"monster\": {\n        \"monster_type\": \"vampire\",\n        \"num_victims\": 10\n    },\n    \"percent\": 0.1,\n    \"birthdate\": \"2023/10/01\",\n    \"percentages\": {\n        \"0.1\": 1,\n        \"0.2\": 2\n    },\n    \"json_properties\": {\"key\": \"value\"},\n    \"matrix\": [[1.0, 2.0], [3.0, 4.0]],\n    \"extra_key\": \"extra_value\"\n}\n\"\"\"\n\nfranken = JSON.parse(json, FrankenStruct)","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"Let's walk through some notable features of the example above:","category":"page"},{"location":"reading/","page":"JSON Reading","title":"JSON Reading","text":"The name field isn't present in the JSON input, so the default value of \"Jim\" is used.\nThe address field uses a default @choosetype to determine that the JSON value is not null, so a String should be parsed for the field value.\nThe rate field has a null JSON value, so the default @choosetype recognizes it should be \"lifted\" to Missing, which then uses a predefined lift definition for Missing.\nThe type field is a Symbol, and has a fieldtag json=(name=\"franken_type\",) which means the JSON key franken_type will be used to set the field value instead of the default type field name. A default lift definition for Symbol is used to convert the JSON string value to a Symbol.\nThe notsure field is of type Any, so the default object type JSON.Object{String, Any} is used to materialize the JSON value.\nThe monster field is a polymorphic type, and the JSON value has a monster_type key that determines which concrete type to use. The @choosetype macro is used to define the logic for choosing the concrete type based on the JSON input. Note that teh x in @choosetype is a LazyValue, so we materialize via x.monster_type[] in order to compare with the string \"vampire\".\nThe percent field is a custom type Percent and the JSON.lift macro defines how to construct a Percent from the JSON value, which is a Float64 in this case.\nThe birthdate field uses a custom date format for parsing, specified in the JSON input.\nThe percentages field is a dictionary with keys of type Percent, which is a custom type. The liftkey function is defined to convert the JSON string keys to Percent types (parses the Float64 manually)\nThe json_properties field has a type of JSONText, which means the raw JSON will be preserved as a String of the JSONText type.\nThe matrix field is a Matrix{Float64}, so the JSON input array-of-arrays are materialized as such.\nThe extra_key field is not defined in the FrankenStruct type, so it is ignored and skipped over.","category":"page"},{"location":"writing/#JSON-Writing","page":"JSON Writing","title":"JSON Writing","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"This guide to writing JSON in the JSON.jl package aims to:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"Provide a comprehensive overview of the JSON serialization process.\nExplain the various options and configurations available for writing JSON data.\nOffer practical examples to illustrate the usage of different functions and options.","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"","category":"page"},{"location":"writing/#Core-JSON-Serialization-JSON.json","page":"JSON Writing","title":"Core JSON Serialization - JSON.json","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"The main entrypoint for serializing Julia values to JSON in JSON.jl is the JSON.json function. This function offers flexible output options:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"# Serialize to a String\nJSON.json(x) -> String\n\n# Serialize to an IO object\nJSON.json(io::IO, x) -> IO\n\n# Serialize to a file\nJSON.json(file_name::String, x) -> String","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"The JSON.json function accepts a wide range of Julia types and transforms them into their JSON representation by knowing how to serialize a core set of types:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"Julia type JSON representation\nNothing null\nBool true or false\nNumber Numeric value (integer or floating point)\nAbstractString String with escaped characters\nAbstractDict/NamedTuple Object ({})\nAbstractVector/Tuple/Set Array ([])\nCustom structs Object ({}) with fields as keys\nJSONText Raw JSON (inserted as-is)","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"For values that don't fall into one of the above categories, JSON.lower will be called allowing a \"domain transformation\" from Julia value to an appropriate representation of the categories above.","category":"page"},{"location":"writing/#Customizing-JSON-Output","page":"JSON Writing","title":"Customizing JSON Output","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"JSON.json supports numerous keyword arguments to control how data is serialized:","category":"page"},{"location":"writing/#Pretty-Printing","page":"JSON Writing","title":"Pretty Printing","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"By default, JSON.json produces compact JSON without extra whitespace. For human-readable output:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"# Boolean flag for default pretty printing (2-space indent)\nJSON.json(x; pretty=true)\n\n# Or specify custom indentation level\nJSON.json(x; pretty=4)  # 4-space indentation","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"Example of pretty printing:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"data = Dict(\"name\" => \"Alice\", \"scores\" => [95, 87, 92])\n\n# Compact output\nJSON.json(data)\n# {\"name\":\"Alice\",\"scores\":[95,87,92]}\n\n# Pretty printed\nJSON.json(data; pretty=true)\n# {\n#   \"name\": \"Alice\",\n#   \"scores\": [\n#     95,\n#     87,\n#     92\n#   ]\n# }","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"When pretty printing, you can also control which arrays get printed inline versus multiline using the inline_limit option:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"JSON.json(data; pretty=true, inline_limit=10)\n# {\n#   \"name\": \"Alice\",\n#   \"scores\": [95, 87, 92]\n# }","category":"page"},{"location":"writing/#Null-and-Empty-Value-Handling","page":"JSON Writing","title":"Null and Empty Value Handling","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"JSON.json provides options to control how nothing, missing, and empty collections are handled:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"struct Person\n    name::String\n    email::Union{String, Nothing}\n    phone::Union{String, Nothing}\n    tags::Vector{String}\nend\n\nperson = Person(\"Alice\", \"alice@example.com\", nothing, String[])\n\n# Default behavior writes all values, including null\nJSON.json(person)\n# {\"name\":\"Alice\",\"email\":\"alice@example.com\",\"phone\":null,\"tags\":[]}\n\n# Exclude null values\nJSON.json(person; omit_null=true)\n# {\"name\":\"Alice\",\"email\":\"alice@example.com\",\"tags\":[]}\n\n# Omit empty collections as well\nJSON.json(person; omit_null=true, omit_empty=true)\n# {\"name\":\"Alice\",\"email\":\"alice@example.com\"}","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"Note that we can also control whether null or empty values are omitted at the type level, either by overloading omit_null/omit_empty functions:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"JSON.omit_null(::Type{Person}) = true","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"Or by using a convenient macro annotation when defining the struct:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"@omit_null struct Person\n    name::String\n    email::Union{String, Nothing}\n    phone::Union{String, Nothing}\n    tags::Vector{String}\nend","category":"page"},{"location":"writing/#Special-Numeric-Values","page":"JSON Writing","title":"Special Numeric Values","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"By default, JSON.json throws an error when trying to serialize NaN, Inf, or -Inf as they are not valid JSON. However, you can enable them with the allownan option:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"numbers = [1.0, NaN, Inf, -Inf]\n\n# Default behavior throws an error\ntry\n    JSON.json(numbers)\ncatch e\n    println(e)\nend\n# ArgumentError(\"NaN not allowed to be written in JSON spec; pass `allownan=true` to allow anyway\")\n\n# With allownan=true\nJSON.json(numbers; allownan=true)\n# [1.0,NaN,Infinity,-Infinity]\n\n# Custom representations\nJSON.json(numbers; allownan=true, nan=\"null\", inf=\"1e999\", ninf=\"-1e999\")\n# [1.0,null,1e999,-1e999]","category":"page"},{"location":"writing/#Float-Formatting","page":"JSON Writing","title":"Float Formatting","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"Control how floating-point numbers are formatted in the JSON output:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"pi_value = [Float64(Ï€)]\n\n# Default format (shortest representation)\nJSON.json(pi_value)\n# [3.141592653589793]\n\n# Fixed decimal notation\nJSON.json(pi_value; float_style=:fixed, float_precision=2)\n# [3.14]\n\n# Scientific notation\nJSON.json(pi_value; float_style=:exp, float_precision=3)\n# [3.142e+00]","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"float_precision must be a positive integer when float_style is :fixed or :exp.","category":"page"},{"location":"writing/#JSON-Lines-Format","page":"JSON Writing","title":"JSON Lines Format","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"The JSON Lines format is useful for streaming records where each line is a JSON value:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"records = [\n    Dict(\"id\" => 1, \"name\" => \"Alice\"),\n    Dict(\"id\" => 2, \"name\" => \"Bob\"),\n    Dict(\"id\" => 3, \"name\" => \"Charlie\")\n]\n\n# Standard JSON array\nJSON.json(records)\n# [{\"id\":1,\"name\":\"Alice\"},{\"id\":2,\"name\":\"Bob\"},{\"id\":3,\"name\":\"Charlie\"}]\n\n# JSON Lines format; each object on its own line, no begining or ending square brackets\nJSON.json(records; jsonlines=true)\n# {\"id\":1,\"name\":\"Alice\"}\n# {\"id\":2,\"name\":\"Bob\"}\n# {\"id\":3,\"name\":\"Charlie\"}","category":"page"},{"location":"writing/#Customizing-Types","page":"JSON Writing","title":"Customizing Types","text":"","category":"section"},{"location":"writing/#Using-JSON.JSONText","page":"JSON Writing","title":"Using JSON.JSONText","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"The JSONText type allows you to insert raw, pre-formatted JSON directly:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"data = Dict(\n    \"name\" => \"Alice\",\n    \"config\" => JSON.JSONText(\"{\\\"theme\\\":\\\"dark\\\",\\\"fontSize\\\":16}\")\n)\n\nJSON.json(data)\n# {\"name\":\"Alice\",\"config\":{\"theme\":\"dark\",\"fontSize\":16}}","category":"page"},{"location":"writing/#Custom-Type-Serialization-with-lower","page":"JSON Writing","title":"Custom Type Serialization with lower","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"For full control over how a type is serialized, you can define a JSON.lower method:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"struct Coordinate\n    lat::Float64\n    lon::Float64\nend\n\n# Serialize as an array instead of an object\nJSON.lower(c::Coordinate) = [c.lat, c.lon]\n\npoint = Coordinate(40.7128, -74.0060)\nJSON.json(point)\n# [40.7128,-74.006]\n\n# For serializing custom formats\nstruct UUID\n    value::String\nend\n\nJSON.lower(u::UUID) = u.value\n\nJSON.json(UUID(\"123e4567-e89b-12d3-a456-426614174000\"))\n# \"123e4567-e89b-12d3-a456-426614174000\"","category":"page"},{"location":"writing/#Custom-Serialization-for-Non-Owned-Types","page":"JSON Writing","title":"Custom Serialization for Non-Owned Types","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"To customize serialization for types you don't own (those from other packages), you can use a custom style:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"using Dates\n\n# Create a custom style that inherits from JSONStyle\nstruct DateTimeStyle <: JSON.JSONStyle end\n\n# Define how to serialize Date and DateTime in this style\nJSON.lower(::DateTimeStyle, d::Date) = string(d)\nJSON.lower(::DateTimeStyle, dt::DateTime) = Dates.format(dt, \"yyyy-mm-dd HH:MM:SS\")\n\n# Use the custom style\nJSON.json(Date(2023, 1, 1); style=DateTimeStyle())\n# \"2023-01-01\"\n\nJSON.json(DateTime(2023, 1, 1, 12, 30, 45); style=DateTimeStyle())\n# \"2023-01-01 12:30:45\"","category":"page"},{"location":"writing/#Customizing-Struct-Serialization","page":"JSON Writing","title":"Customizing Struct Serialization","text":"","category":"section"},{"location":"writing/#Field-Names-and-Tags","page":"JSON Writing","title":"Field Names and Tags","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"The JSON.jl package integrates with StructUtils.jl for fine-grained control over struct serialization. StructUtils.jl provides convenient \"struct\" macros:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"@noarg: generates a \"no-argument\" constructor (T())\n@kwarg: generates an all-keyword-argument constructor, similar to Base.@kwdef; (T(; kw1=v1, kw2=v2, ...))\n@tags/@defaults: convenience macros to enable specifying field defaults and field tags\n@nonstruct: marks a struct as non-struct-like, treating it as a primitive type for serialization","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"Each struct macro also supports the setting of field default values (using the same syntax as Base.@kwdef), as well as specifying \"field tags\" using the &(tag=val,) syntax.","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"using JSON, StructUtils\n\n# Using the @tags macro to customize field serialization\n@tags struct User\n    user_id::Int &(json=(name=\"id\",),)\n    first_name::String &(json=(name=\"firstName\",),)\n    last_name::String &(json=(name=\"lastName\",),)\n    created_at::DateTime &(json=(dateformat=\"yyyy-mm-dd\",),)\n    internal_note::String &(json=(ignore=true,),)\nend\n\nuser = User(123, \"Jane\", \"Doe\", DateTime(2023, 5, 8), \"Private note\")\n\nJSON.json(user)\n# {\"id\":123,\"firstName\":\"Jane\",\"lastName\":\"Doe\",\"created_at\":\"2023-05-08\"}","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"The various field tags allow:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"Renaming fields with name\nCustom date formatting with dateformat\nExcluding fields from JSON output with ignore=true","category":"page"},{"location":"writing/#Default-Values-with-@defaults","page":"JSON Writing","title":"Default Values with @defaults","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"Combine with the @defaults macro to provide default values:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"@defaults struct Configuration\n    port::Int = 8080\n    host::String = \"localhost\"\n    debug::Bool = false\n    timeout::Int = 30\nend\n\nconfig = Configuration(9000)\nJSON.json(config)\n# {\"port\":9000,\"host\":\"localhost\",\"debug\":false,\"timeout\":30}","category":"page"},{"location":"writing/#Handling-Circular-References","page":"JSON Writing","title":"Handling Circular References","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"JSON.json automatically detects circular references to prevent infinite recursion:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"mutable struct Node\n    value::Int\n    next::Union{Nothing, Node}\nend\n\n# Create a circular reference\nnode = Node(1, nothing)\nnode.next = node\n\n# Without circular detection, this would cause a stack overflow\nJSON.json(node; omit_null=false)\n# {\"value\":1,\"next\":null}","category":"page"},{"location":"writing/#Custom-Dictionary-Key-Serialization","page":"JSON Writing","title":"Custom Dictionary Key Serialization","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"For dictionaries with non-string keys, JSON.json has a few default lowerkey definitions to convert keys to strings:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"# Integer keys\nJSON.json(Dict(1 => \"one\", 2 => \"two\"))\n# {\"1\":\"one\",\"2\":\"two\"}\n\n# Symbol keys\nJSON.json(Dict(:name => \"Alice\", :age => 30))\n# {\"name\":\"Alice\",\"age\":30}\n\n# Custom key serialization\nstruct CustomKey\n    id::Int\nend\n\ndict = Dict(CustomKey(1) => \"value1\", CustomKey(2) => \"value2\")\ntry\n    JSON.json(dict)\ncatch e\n    println(e)\nend\n# ArgumentError(\"No key representation for CustomKey. Define StructUtils.lowerkey(::CustomKey)\")\n\n# Define how the key should be converted to a string\nStructUtils.lowerkey(::JSON.JSONStyle, k::CustomKey) = \"key-$(k.id)\"\n\nJSON.json(dict)\n# {\"key-1\":\"value1\",\"key-2\":\"value2\"}","category":"page"},{"location":"writing/#Advanced-Example:-The-FrankenStruct","page":"JSON Writing","title":"Advanced Example: The FrankenStruct","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"Let's explore a comprehensive example that showcases many of JSON.jl's advanced serialization features:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"using Dates, JSON, StructUtils\n\nabstract type AbstractMonster end\n\nstruct Dracula <: AbstractMonster\n    num_victims::Int\nend\n\nstruct Werewolf <: AbstractMonster\n    witching_hour::DateTime\nend\n\nstruct Percent <: Number\n    value::Float64\nend\n\nJSON.lower(x::Percent) = x.value\nStructUtils.lowerkey(x::Percent) = string(x.value)\n\n@noarg mutable struct FrankenStruct\n    id::Int\n    name::String # no default to show serialization of an undefined field\n    address::Union{Nothing, String} = nothing\n    rate::Union{Missing, Float64} = missing\n    type::Symbol = :a &(json=(name=\"franken_type\",),)\n    notsure::Any = JSON.Object(\"key\" => \"value\")\n    monster::AbstractMonster = Dracula(10) &(json=(lower=x -> x isa Dracula ? \n        (monster_type=\"vampire\", num_victims=x.num_victims) : \n        (monster_type=\"werewolf\", witching_hour=x.witching_hour),),)\n    percent::Percent = Percent(0.5)\n    birthdate::Date = Date(2025, 1, 1) &(json=(dateformat=\"yyyy/mm/dd\",),)\n    percentages::Dict{Percent, Int} = Dict{Percent, Int}(Percent(0.0) => 0, Percent(1.0) => 1)\n    json_properties::JSONText = JSONText(\"{\\\"key\\\": \\\"value\\\"}\")\n    matrix::Matrix{Float64} = [1.0 2.0; 3.0 4.0]\n    extra_field::Any = nothing &(json=(ignore=true,),)\nend\n\nfranken = FrankenStruct()\nfranken.id = 1\n\njson = JSON.json(franken)\n# \"{\\\"id\\\":1,\\\"name\\\":null,\\\"address\\\":null,\\\"rate\\\":null,\\\"franken_type\\\":\\\"a\\\",\\\"notsure\\\":{\\\"key\\\":\\\"value\\\"},\\\"monster\\\":{\\\"monster_type\\\":\\\"vampire\\\",\\\"num_victims\\\":10},\\\"percent\\\":0.5,\\\"birthdate\\\":\\\"2025/01/01\\\",\\\"percentages\\\":{\\\"1.0\\\":1,\\\"0.0\\\":0},\\\"json_properties\\\":{\\\"key\\\": \\\"value\\\"},\\\"matrix\\\":[[1.0,3.0],[2.0,4.0]]}\"","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"Let's analyze each part of this complex example to understand how JSON.jl's serialization features work:","category":"page"},{"location":"writing/#Custom-Type-Serialization-Strategy","page":"JSON Writing","title":"Custom Type Serialization Strategy","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"The AbstractMonster Type Hierarchy:\nWe define an abstract type AbstractMonster with two concrete subtypes: Dracula and Werewolf\nEach type contains type-specific data (number of victims vs. witching hour)\nCustom Numeric Type:\nPercent is a custom numeric type that wraps a Float64\nWe provide two serialization methods:\nJSON.lower(x::Percent) = x.value: This tells JSON how to serialize a Percent value (convert to the underlying Float64)\nStructUtils.lowerkey(x::Percent) = string(x.value): This handles when a Percent is used as a dictionary key\nThe FrankenStruct:\nCreated with @noarg making it a mutable struct that can be default constructed like FrankenStruct()","category":"page"},{"location":"writing/#Field-Level-Serialization-Control","page":"JSON Writing","title":"Field-Level Serialization Control","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"Let's examine each field of FrankenStruct in detail:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"Basic Fields: \nid::Int: Standard integer field (initialized explicitly to 1)\nname::String: Intentionally left uninitialized to demonstrate #undef serialization\nNull Handling and Unions:\naddress::Union{Nothing, String} = nothing: Demonstrates how Nothing values are serialized\nrate::Union{Missing, Float64} = missing: Shows how Missing values are serialized (both become null in JSON)\nField Renaming with Tags:\ntype::Symbol = :a &(json=(name=\"franken_type\",),): \nThe name tag changes the output JSON key from \"type\" to \"franken_type\"\nThe value :a is automatically serialized as the string \"a\" through a default lower method for symbols\nAny Type:\nnotsure::Any = JSON.Object(\"key\" => \"value\"): Shows how JSON handles arbitrary types\nField-Specific Custom Serialization:\nmonster::AbstractMonster = Dracula(10) &(json=(lower=x -> x isa Dracula ? \n    (monster_type=\"vampire\", num_victims=x.num_victims) : \n    (monster_type=\"werewolf\", witching_hour=x.witching_hour),),)\nThis demonstrates field-specific custom serialization using the lower field tag\nThe lambda function checks the concrete type and produces a different JSON structure based on the type\nFor Dracula, it adds a \"monster_type\": \"vampire\" field\nFor Werewolf, it would add a \"monster_type\": \"werewolf\" field\nUnlike a global JSON.lower method, this approach only applies when this specific field is serialized\nCustom Numeric Type:\npercent::Percent = Percent(0.5): Uses the global JSON.lower we defined to serialize as 0.5\nCustom Date Formatting:\nbirthdate::Date = Date(2025, 1, 1) &(json=(dateformat=\"yyyy/mm/dd\",),):\nThe dateformat field tag controls how the date is formatted\nInstead of ISO format (\"2025-01-01\"), it's serialized as \"2025/01/01\"\nDictionary with Custom Keys:\npercentages::Dict{Percent, Int} = Dict{Percent, Int}(Percent(0.0) => 0, Percent(1.0) => 1):\nThis dictionary uses our custom Percent type as keys\nJSON uses our StructUtils.lowerkey method to convert the keys to strings\nRaw JSON Inclusion:\njson_properties::JSONText = JSONText(\"{\\\"key\\\": \\\"value\\\"}\"):\nThe JSONText wrapper indicates this should be included as-is in the output\nNo escaping or processing is done; the string is inserted directly into the JSON\nMatrices and Multi-dimensional Arrays:\nmatrix::Matrix{Float64} = [1.0 2.0; 3.0 4.0]:\n2D array serialized as nested arrays in column-major order\nIgnoring Fields:\nextra_field::Any = nothing &(json=(ignore=true,),):\nThe ignore=true field tag means this field will be completely excluded from serialization\nUseful for internal fields that shouldn't be part of the JSON representation","category":"page"},{"location":"writing/#Output-Analysis","page":"JSON Writing","title":"Output Analysis","text":"","category":"section"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"When we serialize this struct, we get a JSON string with all the specialized serialization rules applied:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"{\n  \"id\": 1,\n  \"name\": null,\n  \"address\": null,\n  \"rate\": null,\n  \"franken_type\": \"a\",\n  \"notsure\": {\"key\": \"value\"},\n  \"monster\": {\"monster_type\": \"vampire\", \"num_victims\": 10},\n  \"percent\": 0.5,\n  \"birthdate\": \"2025/01/01\",\n  \"percentages\": {\"1.0\": 1, \"0.0\": 0},\n  \"json_properties\": {\"key\": \"value\"},\n  \"matrix\": [[1.0, 3.0], [2.0, 4.0]]\n}","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"Some key observations:","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"extra_field is completely omitted due to the ignore tag\nField names are either their originals (id, name) or renamed versions (franken_type instead of type)\nThe nested monster field has custom serialization, producing a specialized format\nThe date is in the custom format we specified\nDictionary keys using our custom Percent type are properly converted to strings\nThe matrix is serialized in column-major order as nested arrays\nThe JSONText data is inserted directly without any additional processing","category":"page"},{"location":"writing/","page":"JSON Writing","title":"JSON Writing","text":"This example demonstrates how JSON.jl provides extensive control over JSON serialization at multiple levels: global type rules, field-specific customization, and overall serialization options.","category":"page"}]
}
